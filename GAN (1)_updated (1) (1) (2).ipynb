{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\n\nif torch.cuda.is_available():\n    print(\"GPU is available\")\nelse:\n    print(\"GPU is not available\")","metadata":{"trusted":true,"tags":[]},"execution_count":13,"outputs":[{"name":"stdout","text":"GPU is available\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef get_gpu_info():\n    if torch.cuda.is_available():\n        gpu_info = {}\n        props = torch.cuda.get_device_properties(0)\n        gpu_info['GPU Name'] = props.name\n        gpu_info['Total Memory (MB)'] = props.total_memory // (1024 * 1024)\n        gpu_info['CUDA Capability'] = f\"{props.major}.{props.minor}\"\n        gpu_info['Multiprocessor Count'] = props.multi_processor_count\n\n        return gpu_info\n    else:\n        return \"No GPU available\"\n\nif __name__ == \"__main__\":\n    gpu_info = get_gpu_info()\n    if isinstance(gpu_info, dict):\n        for key, value in gpu_info.items():\n            print(f\"{key}: {value}\")\n    else:\n        print(gpu_info)\n","metadata":{"trusted":true,"tags":[]},"execution_count":14,"outputs":[{"name":"stdout","text":"GPU Name: NVIDIA GeForce RTX 3090\nTotal Memory (MB): 24252\nCUDA Capability: 8.6\nMultiprocessor Count: 82\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import the required libraries\n# For this example we will use pytorch to manage the construction of the neural networks and the training\n# torchvision is a module that is part of pytorch that supports vision datasets and it will be where we will source the mnist - handwritten digits - data\n\nfrom __future__ import print_function\nimport argparse\nimport os\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\n\n","metadata":{"tags":[],"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Setting a seed will determine which data elements are selected. To replicate results keep the same seed.\nmanualSeed = random.randint(1, 10000)\nprint(\"Random Seed: \", manualSeed)\nrandom.seed(manualSeed)\ntorch.manual_seed(manualSeed)\n","metadata":{"tags":[],"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Random Seed:  9772\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7f8c38305f50>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is a check if there is a gpu available for training. At the moment we are assuming that it is not available.\ntorch.cuda.is_available()\n","metadata":{"tags":[],"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"\n# Check if GPU is available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Parameters\ncudnn.benchmark = True\nngpu = 1 if torch.cuda.is_available() else 0\nnz = 100  # Latent space matrix width\nngf = 64  # Generator matrix shape\nndf = 64  # Discriminator matrix shape\nnc = 1  # Number of color channels\nbatch_size = 64  # Number of samples per pass\nworkers = 4  # Number of CPU workers for the dataset\n","metadata":{"tags":[],"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = dset.MNIST(root='data', download=True,\n                      transform=transforms.Compose([\n                          transforms.Resize(64),\n                          transforms.ToTensor(),\n                          transforms.Normalize((0.5,), (0.5,)),\n                      ]))\n\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n                                         shuffle=True, num_workers=int(workers))\n","metadata":{"tags":[],"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100.0%\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100.0%\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100.0%\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100.0%","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n# custom weights initialization called on netG and netD\n# The weights will need to be initialised based on the layer type to some value before training. These could be imported from past training steps.\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n        torch.nn.init.zeros_(m.bias)\n","metadata":{"tags":[],"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# This is the bulk of the neural network definition for the Generator.\n# The init sets up the layers and connecting activation functions.\n# The forward function processes the data through the layers\nclass Generator(nn.Module):\n    def __init__(self, ngpu):\n        super(Generator, self).__init__()\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            # input is Z, going into a convolution\n            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True),\n            # state size. (ngf*8) x 4 x 4\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            # state size. (ngf*4) x 8 x 8\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            # state size. (ngf*2) x 16 x 16\n            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            # state size. (ngf) x 32 x 32\n            nn.ConvTranspose2d(ngf,      nc, 4, 2, 1, bias=False),\n            nn.Tanh()\n            # state size. (nc) x 64 x 64\n        )\n\n    def forward(self, input):\n        if input.is_cuda and self.ngpu > 1:\n            output = nn.parallel.data_parallel(\n                self.main, input, range(self.ngpu))\n        else:\n            output = self.main(input)\n        return output\n\n\nnetG = Generator(ngpu).to(device)\nnetG.apply(weights_init)\nprint(netG)\n","metadata":{"tags":[],"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Generator(\n  (main): Sequential(\n    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU(inplace=True)\n    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (11): ReLU(inplace=True)\n    (12): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (13): Tanh()\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# This is the bulk of the neural network definition for the Discrimator.\n# The init sets up the layers and connecting activation functions.\n# The forward function processes the data through the layers\nclass Discriminator(nn.Module):\n    def __init__(self, ngpu):\n        super(Discriminator, self).__init__()\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            # input is (nc) x 64 x 64\n            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf) x 32 x 32\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*2) x 16 x 16\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*4) x 8 x 8\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*8) x 4 x 4\n            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        if input.is_cuda and self.ngpu > 1:\n            output = nn.parallel.data_parallel(\n                self.main, input, range(self.ngpu))\n        else:\n            output = self.main(input)\n\n        return output.view(-1, 1).squeeze(1)\n    \nnetD = Discriminator(ngpu).to(device)\nnetD.apply(weights_init)\nprint(netD)","metadata":{"tags":[],"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Discriminator(\n  (main): Sequential(\n    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n    (12): Sigmoid()\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the loss function from pytorches established modules\ncriterion = nn.BCELoss()\n\n# Set up the initial noise of the latent space to sample from.\n# Set the label of a real and fake sample to 0,1\nfixed_noise = torch.randn(64, nz, 1, 1, device=device)\nreal_label = 1\nfake_label = 0\n\n# Create the optimiser which will dynamically change the parameters of the learning function over time to imporve the training process\noptimizerD = optim.Adam(netD.parameters(), lr=0.0005, betas=(0.5, 0.999))\noptimizerG = optim.Adam(netG.parameters(), lr=0.0005, betas=(0.5, 0.999))\n","metadata":{"tags":[],"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1):\n    for i, data in enumerate(dataloader, 0):\n        ############################\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ###########################\n        # train with real\n        \n        # Set the descrimator to forget any gradients.\n        netD.zero_grad()\n        # Get a sample of real handwritten digits and label them as 1 - all real\n        real_cpu = data[0].to(device)\n        batch_size = real_cpu.size(0)\n        label = torch.full((batch_size,), real_label, dtype=real_cpu.dtype, device=device)\n        # Pass the sample through the descrimator\n        output = netD(real_cpu)\n        # measure the error\n        errD_real = criterion(output, label)\n        # Calculate the gradients of each layer of the network\n        errD_real.backward()\n        # Get the average of the output across the batch\n        D_x = output.mean().item()\n\n        # train with fake\n        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n        # pass the noise through the generator layers\n        fake = netG(noise)\n        # set the labels to all 0 - fake\n        label.fill_(fake_label)\n        # ask the descrimator to judge the fake images\n        output = netD(fake.detach())\n        # measure the error\n        errD_fake = criterion(output, label)\n        # Calculate the gradients \n        errD_fake.backward()\n        # Get the average output across the batch again\n        D_G_z1 = output.mean().item()\n        # Get the error\n        errD = errD_real + errD_fake\n        # Run the optimizer to update the weights\n        optimizerD.step()\n\n        ############################\n        # (2) Update G network: maximize log(D(G(z)))\n        ###########################\n        # Set the gradients of the generator to zero\n        netG.zero_grad()\n        label.fill_(real_label)  # fake labels are real for generator cost\n        # get the judgements from the descrimator of the generator output is fake\n        output = netD(fake)\n        # calculate the error\n        errG = criterion(output, label)\n        # update the gradients\n        errG.backward()\n        # Get the average of the output across the batch\n        D_G_z2 = output.mean().item()\n        # update the weights\n        optimizerG.step()\n\n        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n              % (epoch, 1, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n        # every 100 steps save a real sample and a fake sample for comparison\n        if i % 100 == 0:\n            vutils.save_image(real_cpu, 'real_samples.png', normalize=True)\n            fake = netG(fixed_noise)\n            vutils.save_image(fake.detach(), 'fake_samples_epoch_%03d.png' % epoch, normalize=True)\n","metadata":{"tags":[],"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[0/1][0/938] Loss_D: 1.7782 Loss_G: 12.3799 D(x): 0.5280 D(G(z)): 0.5843 / 0.0000\n[0/1][1/938] Loss_D: 4.8980 Loss_G: 14.1061 D(x): 0.9999 D(G(z)): 0.9859 / 0.0000\n[0/1][2/938] Loss_D: 0.4470 Loss_G: 15.9369 D(x): 0.9871 D(G(z)): 0.3105 / 0.0000\n[0/1][3/938] Loss_D: 0.7976 Loss_G: 5.3191 D(x): 0.7042 D(G(z)): 0.0244 / 0.0083\n[0/1][4/938] Loss_D: 5.1032 Loss_G: 22.8838 D(x): 0.9746 D(G(z)): 0.9865 / 0.0000\n[0/1][5/938] Loss_D: 0.2861 Loss_G: 22.6269 D(x): 0.8507 D(G(z)): 0.0000 / 0.0000\n[0/1][6/938] Loss_D: 0.3236 Loss_G: 7.4387 D(x): 0.8885 D(G(z)): 0.0022 / 0.0017\n[0/1][7/938] Loss_D: 6.9209 Loss_G: 27.0062 D(x): 0.9819 D(G(z)): 0.9975 / 0.0000\n[0/1][8/938] Loss_D: 1.4033 Loss_G: 26.0488 D(x): 0.4960 D(G(z)): 0.0000 / 0.0000\n[0/1][9/938] Loss_D: 0.2062 Loss_G: 10.7406 D(x): 0.9460 D(G(z)): 0.0001 / 0.0001\n[0/1][10/938] Loss_D: 4.2189 Loss_G: 30.2608 D(x): 0.9975 D(G(z)): 0.9705 / 0.0000\n[0/1][11/938] Loss_D: 0.6301 Loss_G: 35.2016 D(x): 0.7654 D(G(z)): 0.0000 / 0.0000\n[0/1][12/938] Loss_D: 0.8257 Loss_G: 35.3447 D(x): 0.7479 D(G(z)): 0.0000 / 0.0000\n[0/1][13/938] Loss_D: 0.0264 Loss_G: 34.8970 D(x): 0.9802 D(G(z)): 0.0000 / 0.0000\n[0/1][14/938] Loss_D: 0.0290 Loss_G: 34.2860 D(x): 0.9822 D(G(z)): 0.0000 / 0.0000\n[0/1][15/938] Loss_D: 0.0007 Loss_G: 33.5660 D(x): 0.9993 D(G(z)): 0.0000 / 0.0000\n[0/1][16/938] Loss_D: 0.0245 Loss_G: 32.7320 D(x): 0.9835 D(G(z)): 0.0000 / 0.0000\n[0/1][17/938] Loss_D: 0.0000 Loss_G: 30.3471 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n[0/1][18/938] Loss_D: 0.0001 Loss_G: 21.2072 D(x): 0.9999 D(G(z)): 0.0000 / 0.0000\n[0/1][19/938] Loss_D: 6.6937 Loss_G: 36.3829 D(x): 0.9999 D(G(z)): 0.9957 / 0.0000\n[0/1][20/938] Loss_D: 2.8125 Loss_G: 36.8548 D(x): 0.2737 D(G(z)): 0.0000 / 0.0000\n[0/1][21/938] Loss_D: 0.0310 Loss_G: 36.7151 D(x): 0.9762 D(G(z)): 0.0000 / 0.0000\n[0/1][22/938] Loss_D: 0.0141 Loss_G: 36.4061 D(x): 0.9873 D(G(z)): 0.0000 / 0.0000\n[0/1][23/938] Loss_D: 0.0260 Loss_G: 36.2305 D(x): 0.9791 D(G(z)): 0.0000 / 0.0000\n[0/1][24/938] Loss_D: 0.1368 Loss_G: 35.5813 D(x): 0.9444 D(G(z)): 0.0000 / 0.0000\n[0/1][25/938] Loss_D: 0.0078 Loss_G: 35.4737 D(x): 0.9933 D(G(z)): 0.0000 / 0.0000\n[0/1][26/938] Loss_D: 0.0009 Loss_G: 34.9418 D(x): 0.9991 D(G(z)): 0.0000 / 0.0000\n[0/1][27/938] Loss_D: 0.0001 Loss_G: 35.0641 D(x): 0.9999 D(G(z)): 0.0000 / 0.0000\n[0/1][28/938] Loss_D: 0.0002 Loss_G: 34.3847 D(x): 0.9998 D(G(z)): 0.0000 / 0.0000\n[0/1][29/938] Loss_D: 0.0033 Loss_G: 33.7552 D(x): 0.9970 D(G(z)): 0.0000 / 0.0000\n[0/1][30/938] Loss_D: 0.0002 Loss_G: 33.1299 D(x): 0.9998 D(G(z)): 0.0000 / 0.0000\n[0/1][31/938] Loss_D: 0.0001 Loss_G: 31.1022 D(x): 0.9999 D(G(z)): 0.0000 / 0.0000\n[0/1][32/938] Loss_D: 0.0000 Loss_G: 25.6452 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n[0/1][33/938] Loss_D: 0.0193 Loss_G: 7.9383 D(x): 0.9993 D(G(z)): 0.0179 / 0.0030\n[0/1][34/938] Loss_D: 28.1630 Loss_G: 26.0896 D(x): 0.9999 D(G(z)): 0.9997 / 0.0000\n[0/1][35/938] Loss_D: 2.2851 Loss_G: 21.2009 D(x): 0.3867 D(G(z)): 0.0000 / 0.0000\n[0/1][36/938] Loss_D: 0.3143 Loss_G: 10.6207 D(x): 0.9051 D(G(z)): 0.0001 / 0.0003\n[0/1][37/938] Loss_D: 3.0113 Loss_G: 23.7810 D(x): 0.9569 D(G(z)): 0.6863 / 0.0000\n[0/1][38/938] Loss_D: 2.0359 Loss_G: 18.0558 D(x): 0.5055 D(G(z)): 0.0000 / 0.0000\n[0/1][39/938] Loss_D: 0.3613 Loss_G: 5.1838 D(x): 0.8953 D(G(z)): 0.0242 / 0.0336\n[0/1][40/938] Loss_D: 5.5885 Loss_G: 27.2993 D(x): 0.9593 D(G(z)): 0.8777 / 0.0000\n[0/1][41/938] Loss_D: 6.7427 Loss_G: 15.4294 D(x): 0.0208 D(G(z)): 0.0000 / 0.0000\n[0/1][42/938] Loss_D: 0.1729 Loss_G: 4.5232 D(x): 0.9510 D(G(z)): 0.0623 / 0.0851\n[0/1][43/938] Loss_D: 5.0760 Loss_G: 16.2889 D(x): 0.9603 D(G(z)): 0.8323 / 0.0000\n[0/1][44/938] Loss_D: 1.8354 Loss_G: 12.5222 D(x): 0.5000 D(G(z)): 0.0003 / 0.0001\n[0/1][45/938] Loss_D: 0.5113 Loss_G: 5.2578 D(x): 0.8395 D(G(z)): 0.1780 / 0.0087\n[0/1][46/938] Loss_D: 1.5777 Loss_G: 13.3947 D(x): 0.8918 D(G(z)): 0.5308 / 0.0000\n[0/1][47/938] Loss_D: 2.7651 Loss_G: 6.1437 D(x): 0.2157 D(G(z)): 0.0002 / 0.0221\n[0/1][48/938] Loss_D: 0.8109 Loss_G: 6.2715 D(x): 0.9528 D(G(z)): 0.4193 / 0.0029\n[0/1][49/938] Loss_D: 1.1365 Loss_G: 13.8862 D(x): 0.9400 D(G(z)): 0.5142 / 0.0000\n[0/1][50/938] Loss_D: 3.7866 Loss_G: 4.3164 D(x): 0.2004 D(G(z)): 0.0004 / 0.0683\n[0/1][51/938] Loss_D: 0.8750 Loss_G: 3.7602 D(x): 0.8836 D(G(z)): 0.3984 / 0.0421\n[0/1][52/938] Loss_D: 0.4883 Loss_G: 6.9478 D(x): 0.9314 D(G(z)): 0.2911 / 0.0017\n[0/1][53/938] Loss_D: 0.3074 Loss_G: 5.2742 D(x): 0.8120 D(G(z)): 0.0255 / 0.0074\n[0/1][54/938] Loss_D: 0.3870 Loss_G: 4.9209 D(x): 0.8617 D(G(z)): 0.1853 / 0.0122\n[0/1][55/938] Loss_D: 0.5875 Loss_G: 6.9894 D(x): 0.8665 D(G(z)): 0.3100 / 0.0023\n[0/1][56/938] Loss_D: 1.0380 Loss_G: 1.6433 D(x): 0.5078 D(G(z)): 0.0497 / 0.2438\n[0/1][57/938] Loss_D: 2.6452 Loss_G: 13.8979 D(x): 0.9846 D(G(z)): 0.8684 / 0.0000\n[0/1][58/938] Loss_D: 2.4273 Loss_G: 8.5186 D(x): 0.2604 D(G(z)): 0.0004 / 0.0012\n[0/1][59/938] Loss_D: 0.2248 Loss_G: 2.1534 D(x): 0.9442 D(G(z)): 0.1405 / 0.1595\n[0/1][60/938] Loss_D: 3.0703 Loss_G: 8.7342 D(x): 0.9659 D(G(z)): 0.8966 / 0.0024\n[0/1][61/938] Loss_D: 1.5608 Loss_G: 6.1446 D(x): 0.3856 D(G(z)): 0.0102 / 0.0110\n[0/1][62/938] Loss_D: 0.8708 Loss_G: 1.5281 D(x): 0.5875 D(G(z)): 0.0509 / 0.2885\n[0/1][63/938] Loss_D: 1.8336 Loss_G: 7.3310 D(x): 0.9439 D(G(z)): 0.7672 / 0.0029\n[0/1][64/938] Loss_D: 0.7718 Loss_G: 5.6007 D(x): 0.5960 D(G(z)): 0.0169 / 0.0085\n[0/1][65/938] Loss_D: 0.3579 Loss_G: 3.2550 D(x): 0.8433 D(G(z)): 0.1104 / 0.0638\n[0/1][66/938] Loss_D: 1.1208 Loss_G: 8.0470 D(x): 0.8653 D(G(z)): 0.5445 / 0.0009\n[0/1][67/938] Loss_D: 1.0830 Loss_G: 4.8884 D(x): 0.4785 D(G(z)): 0.0058 / 0.0121\n[0/1][68/938] Loss_D: 0.3368 Loss_G: 2.9928 D(x): 0.8883 D(G(z)): 0.1708 / 0.0676\n[0/1][69/938] Loss_D: 1.2704 Loss_G: 9.0364 D(x): 0.9471 D(G(z)): 0.6457 / 0.0003\n[0/1][70/938] Loss_D: 1.0263 Loss_G: 6.6400 D(x): 0.4794 D(G(z)): 0.0046 / 0.0042\n[0/1][71/938] Loss_D: 0.4275 Loss_G: 2.4604 D(x): 0.7644 D(G(z)): 0.0746 / 0.1549\n[0/1][72/938] Loss_D: 1.1664 Loss_G: 6.2198 D(x): 0.9429 D(G(z)): 0.5997 / 0.0044\n[0/1][73/938] Loss_D: 0.3357 Loss_G: 5.6889 D(x): 0.8087 D(G(z)): 0.0541 / 0.0109\n[0/1][74/938] Loss_D: 0.7120 Loss_G: 2.2477 D(x): 0.6453 D(G(z)): 0.0986 / 0.1765\n[0/1][75/938] Loss_D: 1.3347 Loss_G: 5.5729 D(x): 0.9574 D(G(z)): 0.6470 / 0.0062\n[0/1][76/938] Loss_D: 0.9350 Loss_G: 3.2797 D(x): 0.5167 D(G(z)): 0.0578 / 0.0714\n[0/1][77/938] Loss_D: 0.8309 Loss_G: 3.6261 D(x): 0.8158 D(G(z)): 0.3591 / 0.0534\n[0/1][78/938] Loss_D: 0.5239 Loss_G: 4.4631 D(x): 0.8438 D(G(z)): 0.2275 / 0.0167\n[0/1][79/938] Loss_D: 0.4227 Loss_G: 3.3951 D(x): 0.7760 D(G(z)): 0.0932 / 0.0457\n[0/1][80/938] Loss_D: 0.5403 Loss_G: 4.1503 D(x): 0.8511 D(G(z)): 0.2471 / 0.0209\n[0/1][81/938] Loss_D: 0.6053 Loss_G: 4.0715 D(x): 0.7765 D(G(z)): 0.1792 / 0.0226\n[0/1][82/938] Loss_D: 0.4573 Loss_G: 3.5340 D(x): 0.8085 D(G(z)): 0.1559 / 0.0403\n[0/1][83/938] Loss_D: 0.7201 Loss_G: 5.7455 D(x): 0.8228 D(G(z)): 0.3656 / 0.0048\n[0/1][84/938] Loss_D: 1.1502 Loss_G: 0.9953 D(x): 0.4734 D(G(z)): 0.1145 / 0.4081\n[0/1][85/938] Loss_D: 2.1009 Loss_G: 10.2994 D(x): 0.9623 D(G(z)): 0.8452 / 0.0001\n[0/1][86/938] Loss_D: 2.8242 Loss_G: 4.3406 D(x): 0.1447 D(G(z)): 0.0018 / 0.0518\n[0/1][87/938] Loss_D: 0.8108 Loss_G: 3.4634 D(x): 0.8697 D(G(z)): 0.3700 / 0.0495\n[0/1][88/938] Loss_D: 0.9712 Loss_G: 6.5343 D(x): 0.8251 D(G(z)): 0.4278 / 0.0070\n[0/1][89/938] Loss_D: 0.8431 Loss_G: 2.9817 D(x): 0.5802 D(G(z)): 0.0493 / 0.1285\n[0/1][90/938] Loss_D: 0.9561 Loss_G: 5.3071 D(x): 0.8953 D(G(z)): 0.4701 / 0.0078\n[0/1][91/938] Loss_D: 0.5056 Loss_G: 3.7366 D(x): 0.7237 D(G(z)): 0.0625 / 0.0396\n[0/1][92/938] Loss_D: 0.6110 Loss_G: 2.5656 D(x): 0.7430 D(G(z)): 0.1940 / 0.1102\n[0/1][93/938] Loss_D: 0.8044 Loss_G: 6.7075 D(x): 0.9190 D(G(z)): 0.4536 / 0.0025\n[0/1][94/938] Loss_D: 1.1406 Loss_G: 1.9111 D(x): 0.4420 D(G(z)): 0.0408 / 0.2405\n[0/1][95/938] Loss_D: 1.5444 Loss_G: 6.2690 D(x): 0.9231 D(G(z)): 0.6125 / 0.0071\n[0/1][96/938] Loss_D: 0.8003 Loss_G: 3.6690 D(x): 0.5804 D(G(z)): 0.0573 / 0.0475\n[0/1][97/938] Loss_D: 0.5554 Loss_G: 3.8465 D(x): 0.8756 D(G(z)): 0.2544 / 0.0345\n[0/1][98/938] Loss_D: 0.5183 Loss_G: 4.7209 D(x): 0.8647 D(G(z)): 0.2531 / 0.0138\n[0/1][99/938] Loss_D: 0.5182 Loss_G: 3.0115 D(x): 0.7244 D(G(z)): 0.0811 / 0.0697\n[0/1][100/938] Loss_D: 0.6111 Loss_G: 4.7967 D(x): 0.8602 D(G(z)): 0.3180 / 0.0145\n[0/1][101/938] Loss_D: 0.3722 Loss_G: 4.0383 D(x): 0.8030 D(G(z)): 0.0813 / 0.0303\n[0/1][102/938] Loss_D: 0.5518 Loss_G: 5.0899 D(x): 0.8548 D(G(z)): 0.2620 / 0.0102\n[0/1][103/938] Loss_D: 0.4920 Loss_G: 2.4658 D(x): 0.7648 D(G(z)): 0.0698 / 0.1191\n[0/1][104/938] Loss_D: 1.1190 Loss_G: 10.0258 D(x): 0.9139 D(G(z)): 0.5553 / 0.0001\n[0/1][105/938] Loss_D: 3.6681 Loss_G: 0.4919 D(x): 0.0675 D(G(z)): 0.0009 / 0.6639\n[0/1][106/938] Loss_D: 1.6199 Loss_G: 5.1323 D(x): 0.9628 D(G(z)): 0.7239 / 0.0104\n[0/1][107/938] Loss_D: 0.9470 Loss_G: 2.3372 D(x): 0.4760 D(G(z)): 0.0323 / 0.1433\n[0/1][108/938] Loss_D: 0.5798 Loss_G: 2.4139 D(x): 0.9041 D(G(z)): 0.3429 / 0.1090\n[0/1][109/938] Loss_D: 0.5987 Loss_G: 3.0524 D(x): 0.8121 D(G(z)): 0.2757 / 0.0633\n[0/1][110/938] Loss_D: 0.6219 Loss_G: 2.2345 D(x): 0.7054 D(G(z)): 0.1731 / 0.1386\n[0/1][111/938] Loss_D: 0.6093 Loss_G: 2.2464 D(x): 0.7739 D(G(z)): 0.2402 / 0.1460\n[0/1][112/938] Loss_D: 0.7169 Loss_G: 2.9267 D(x): 0.8093 D(G(z)): 0.3186 / 0.0683\n[0/1][113/938] Loss_D: 0.4403 Loss_G: 3.0568 D(x): 0.8189 D(G(z)): 0.1763 / 0.0662\n[0/1][114/938] Loss_D: 0.4691 Loss_G: 2.5866 D(x): 0.7928 D(G(z)): 0.1542 / 0.0980\n[0/1][115/938] Loss_D: 0.5084 Loss_G: 4.1737 D(x): 0.9071 D(G(z)): 0.2983 / 0.0213\n[0/1][116/938] Loss_D: 0.6715 Loss_G: 2.0990 D(x): 0.6179 D(G(z)): 0.0669 / 0.1787\n[0/1][117/938] Loss_D: 0.5623 Loss_G: 4.2936 D(x): 0.9228 D(G(z)): 0.3331 / 0.0201\n[0/1][118/938] Loss_D: 0.2416 Loss_G: 4.3977 D(x): 0.8824 D(G(z)): 0.0832 / 0.0162\n[0/1][119/938] Loss_D: 0.4061 Loss_G: 2.2624 D(x): 0.7787 D(G(z)): 0.0724 / 0.1312\n[0/1][120/938] Loss_D: 0.7008 Loss_G: 5.8899 D(x): 0.9436 D(G(z)): 0.4414 / 0.0066\n[0/1][121/938] Loss_D: 1.0200 Loss_G: 1.6302 D(x): 0.4791 D(G(z)): 0.0128 / 0.2496\n[0/1][122/938] Loss_D: 0.9525 Loss_G: 5.5930 D(x): 0.9350 D(G(z)): 0.5428 / 0.0059\n[0/1][123/938] Loss_D: 0.9977 Loss_G: 1.9679 D(x): 0.4944 D(G(z)): 0.0157 / 0.1707\n[0/1][124/938] Loss_D: 0.5721 Loss_G: 4.2204 D(x): 0.9320 D(G(z)): 0.3654 / 0.0223\n[0/1][125/938] Loss_D: 0.7158 Loss_G: 1.0664 D(x): 0.6039 D(G(z)): 0.0590 / 0.3713\n[0/1][126/938] Loss_D: 1.1149 Loss_G: 6.1982 D(x): 0.9357 D(G(z)): 0.6159 / 0.0036\n[0/1][127/938] Loss_D: 1.8320 Loss_G: 1.3086 D(x): 0.2746 D(G(z)): 0.0071 / 0.3410\n[0/1][128/938] Loss_D: 1.0041 Loss_G: 4.2957 D(x): 0.9838 D(G(z)): 0.5588 / 0.0267\n[0/1][129/938] Loss_D: 0.4872 Loss_G: 3.2248 D(x): 0.7451 D(G(z)): 0.1144 / 0.0535\n[0/1][130/938] Loss_D: 0.8575 Loss_G: 3.5858 D(x): 0.7603 D(G(z)): 0.3787 / 0.0391\n[0/1][131/938] Loss_D: 0.9349 Loss_G: 2.3816 D(x): 0.6086 D(G(z)): 0.1959 / 0.1326\n[0/1][132/938] Loss_D: 0.3561 Loss_G: 4.6897 D(x): 0.9245 D(G(z)): 0.2238 / 0.0137\n[0/1][133/938] Loss_D: 0.2668 Loss_G: 3.8137 D(x): 0.8528 D(G(z)): 0.0772 / 0.0285\n[0/1][134/938] Loss_D: 0.3700 Loss_G: 4.0778 D(x): 0.9022 D(G(z)): 0.1919 / 0.0246\n[0/1][135/938] Loss_D: 0.2803 Loss_G: 3.8861 D(x): 0.8699 D(G(z)): 0.1004 / 0.0303\n[0/1][136/938] Loss_D: 0.3124 Loss_G: 4.2692 D(x): 0.9126 D(G(z)): 0.1701 / 0.0274\n[0/1][137/938] Loss_D: 0.4301 Loss_G: 2.4289 D(x): 0.7852 D(G(z)): 0.1056 / 0.1247\n[0/1][138/938] Loss_D: 0.6013 Loss_G: 7.5470 D(x): 0.9675 D(G(z)): 0.3879 / 0.0009\n[0/1][139/938] Loss_D: 0.9393 Loss_G: 1.9039 D(x): 0.4904 D(G(z)): 0.0118 / 0.2195\n[0/1][140/938] Loss_D: 0.8705 Loss_G: 9.1289 D(x): 0.9690 D(G(z)): 0.4936 / 0.0003\n[0/1][141/938] Loss_D: 2.7159 Loss_G: 2.7235 D(x): 0.1481 D(G(z)): 0.0065 / 0.1281\n[0/1][142/938] Loss_D: 0.8497 Loss_G: 1.5552 D(x): 0.7112 D(G(z)): 0.2525 / 0.2615\n[0/1][143/938] Loss_D: 0.8922 Loss_G: 3.6750 D(x): 0.8436 D(G(z)): 0.4397 / 0.0408\n[0/1][144/938] Loss_D: 0.9495 Loss_G: 0.7000 D(x): 0.4799 D(G(z)): 0.0660 / 0.5847\n[0/1][145/938] Loss_D: 2.1680 Loss_G: 5.9276 D(x): 0.9853 D(G(z)): 0.7949 / 0.0054\n[0/1][146/938] Loss_D: 1.4773 Loss_G: 1.8886 D(x): 0.3179 D(G(z)): 0.0238 / 0.2297\n[0/1][147/938] Loss_D: 1.0667 Loss_G: 3.1011 D(x): 0.9082 D(G(z)): 0.5348 / 0.0794\n[0/1][148/938] Loss_D: 0.9974 Loss_G: 2.8036 D(x): 0.6667 D(G(z)): 0.3195 / 0.0976\n[0/1][149/938] Loss_D: 1.2674 Loss_G: 1.3860 D(x): 0.5175 D(G(z)): 0.2889 / 0.3192\n[0/1][150/938] Loss_D: 1.2008 Loss_G: 3.4579 D(x): 0.7645 D(G(z)): 0.5179 / 0.0486\n[0/1][151/938] Loss_D: 1.0931 Loss_G: 0.9399 D(x): 0.4576 D(G(z)): 0.1164 / 0.4306\n[0/1][152/938] Loss_D: 1.1841 Loss_G: 4.2960 D(x): 0.8888 D(G(z)): 0.5988 / 0.0202\n[0/1][153/938] Loss_D: 1.0763 Loss_G: 1.4261 D(x): 0.4203 D(G(z)): 0.0564 / 0.3120\n[0/1][154/938] Loss_D: 0.8731 Loss_G: 3.4139 D(x): 0.8919 D(G(z)): 0.4558 / 0.0455\n[0/1][155/938] Loss_D: 0.4519 Loss_G: 2.9510 D(x): 0.7587 D(G(z)): 0.1245 / 0.0730\n[0/1][156/938] Loss_D: 0.5420 Loss_G: 2.1797 D(x): 0.7725 D(G(z)): 0.2003 / 0.1427\n[0/1][157/938] Loss_D: 0.6719 Loss_G: 2.7861 D(x): 0.8136 D(G(z)): 0.3094 / 0.0894\n[0/1][158/938] Loss_D: 0.6993 Loss_G: 3.1045 D(x): 0.7544 D(G(z)): 0.2714 / 0.0630\n[0/1][159/938] Loss_D: 0.8631 Loss_G: 1.1532 D(x): 0.5694 D(G(z)): 0.1446 / 0.3621\n[0/1][160/938] Loss_D: 1.0013 Loss_G: 4.9607 D(x): 0.9039 D(G(z)): 0.5236 / 0.0124\n[0/1][161/938] Loss_D: 1.5011 Loss_G: 1.0266 D(x): 0.3364 D(G(z)): 0.0246 / 0.4227\n[0/1][162/938] Loss_D: 1.0941 Loss_G: 4.0232 D(x): 0.9272 D(G(z)): 0.5818 / 0.0235\n[0/1][163/938] Loss_D: 0.6338 Loss_G: 2.4687 D(x): 0.6577 D(G(z)): 0.1043 / 0.1127\n[0/1][164/938] Loss_D: 0.6937 Loss_G: 2.8937 D(x): 0.7662 D(G(z)): 0.2870 / 0.0707\n[0/1][165/938] Loss_D: 0.4676 Loss_G: 2.7234 D(x): 0.7801 D(G(z)): 0.1571 / 0.0931\n[0/1][166/938] Loss_D: 0.4425 Loss_G: 3.2652 D(x): 0.8495 D(G(z)): 0.2085 / 0.0528\n[0/1][167/938] Loss_D: 0.5167 Loss_G: 3.3859 D(x): 0.8250 D(G(z)): 0.2081 / 0.0524\n[0/1][168/938] Loss_D: 0.7138 Loss_G: 1.8800 D(x): 0.6810 D(G(z)): 0.2092 / 0.2050\n[0/1][169/938] Loss_D: 1.0457 Loss_G: 4.7215 D(x): 0.8765 D(G(z)): 0.5333 / 0.0120\n[0/1][170/938] Loss_D: 1.1355 Loss_G: 1.2287 D(x): 0.4317 D(G(z)): 0.0678 / 0.3750\n[0/1][171/938] Loss_D: 0.8546 Loss_G: 4.0538 D(x): 0.9281 D(G(z)): 0.4528 / 0.0308\n[0/1][172/938] Loss_D: 0.4387 Loss_G: 3.2405 D(x): 0.7671 D(G(z)): 0.1104 / 0.0538\n[0/1][173/938] Loss_D: 0.4195 Loss_G: 3.1992 D(x): 0.8529 D(G(z)): 0.1938 / 0.0525\n[0/1][174/938] Loss_D: 0.3500 Loss_G: 3.2468 D(x): 0.8494 D(G(z)): 0.1461 / 0.0573\n[0/1][175/938] Loss_D: 0.4686 Loss_G: 3.1046 D(x): 0.8079 D(G(z)): 0.1876 / 0.0635\n[0/1][176/938] Loss_D: 0.5322 Loss_G: 2.7681 D(x): 0.7760 D(G(z)): 0.1807 / 0.0874\n[0/1][177/938] Loss_D: 0.7016 Loss_G: 5.0722 D(x): 0.8493 D(G(z)): 0.3531 / 0.0115\n[0/1][178/938] Loss_D: 1.3601 Loss_G: 0.2204 D(x): 0.3456 D(G(z)): 0.0537 / 0.8190\n[0/1][179/938] Loss_D: 2.0057 Loss_G: 7.3436 D(x): 0.9815 D(G(z)): 0.8072 / 0.0023\n[0/1][180/938] Loss_D: 1.7471 Loss_G: 2.6388 D(x): 0.2711 D(G(z)): 0.0089 / 0.1224\n[0/1][181/938] Loss_D: 0.6593 Loss_G: 1.9451 D(x): 0.8790 D(G(z)): 0.3643 / 0.1740\n[0/1][182/938] Loss_D: 0.6723 Loss_G: 4.6014 D(x): 0.8911 D(G(z)): 0.3814 / 0.0212\n[0/1][183/938] Loss_D: 1.0029 Loss_G: 1.6456 D(x): 0.4735 D(G(z)): 0.0526 / 0.2556\n[0/1][184/938] Loss_D: 0.5759 Loss_G: 2.5368 D(x): 0.8993 D(G(z)): 0.3248 / 0.1183\n[0/1][185/938] Loss_D: 0.5961 Loss_G: 4.2520 D(x): 0.8985 D(G(z)): 0.3354 / 0.0218\n[0/1][186/938] Loss_D: 0.7804 Loss_G: 1.8395 D(x): 0.5321 D(G(z)): 0.0413 / 0.2239\n[0/1][187/938] Loss_D: 0.7992 Loss_G: 3.3523 D(x): 0.8889 D(G(z)): 0.4251 / 0.0499\n[0/1][188/938] Loss_D: 0.4494 Loss_G: 3.0043 D(x): 0.7597 D(G(z)): 0.1122 / 0.0771\n[0/1][189/938] Loss_D: 0.5297 Loss_G: 2.2139 D(x): 0.7743 D(G(z)): 0.1846 / 0.1471\n[0/1][190/938] Loss_D: 0.5927 Loss_G: 4.3690 D(x): 0.9174 D(G(z)): 0.3518 / 0.0215\n[0/1][191/938] Loss_D: 0.7215 Loss_G: 1.8625 D(x): 0.5861 D(G(z)): 0.0780 / 0.2251\n[0/1][192/938] Loss_D: 0.5283 Loss_G: 4.2049 D(x): 0.9470 D(G(z)): 0.3419 / 0.0217\n[0/1][193/938] Loss_D: 0.4477 Loss_G: 3.0492 D(x): 0.7502 D(G(z)): 0.0878 / 0.0703\n[0/1][194/938] Loss_D: 0.3481 Loss_G: 3.3143 D(x): 0.9027 D(G(z)): 0.1837 / 0.0555\n[0/1][195/938] Loss_D: 0.3283 Loss_G: 3.7839 D(x): 0.8726 D(G(z)): 0.1484 / 0.0298\n[0/1][196/938] Loss_D: 0.3981 Loss_G: 3.0305 D(x): 0.8139 D(G(z)): 0.1306 / 0.0751\n[0/1][197/938] Loss_D: 0.3614 Loss_G: 4.0751 D(x): 0.8969 D(G(z)): 0.1922 / 0.0277\n[0/1][198/938] Loss_D: 0.4434 Loss_G: 3.8460 D(x): 0.8322 D(G(z)): 0.1835 / 0.0363\n[0/1][199/938] Loss_D: 0.4004 Loss_G: 2.7517 D(x): 0.7927 D(G(z)): 0.1177 / 0.0888\n[0/1][200/938] Loss_D: 0.5756 Loss_G: 3.8133 D(x): 0.8127 D(G(z)): 0.2697 / 0.0290\n[0/1][201/938] Loss_D: 0.3241 Loss_G: 2.9476 D(x): 0.8161 D(G(z)): 0.0939 / 0.0753\n[0/1][202/938] Loss_D: 0.3416 Loss_G: 4.2222 D(x): 0.9240 D(G(z)): 0.2089 / 0.0205\n[0/1][203/938] Loss_D: 0.3024 Loss_G: 2.5398 D(x): 0.8118 D(G(z)): 0.0652 / 0.1077\n[0/1][204/938] Loss_D: 0.4336 Loss_G: 4.0424 D(x): 0.8980 D(G(z)): 0.2383 / 0.0296\n[0/1][205/938] Loss_D: 0.3940 Loss_G: 1.6514 D(x): 0.7571 D(G(z)): 0.0497 / 0.2291\n[0/1][206/938] Loss_D: 0.8093 Loss_G: 7.8329 D(x): 0.9687 D(G(z)): 0.4976 / 0.0010\n[0/1][207/938] Loss_D: 2.9021 Loss_G: 0.2913 D(x): 0.1061 D(G(z)): 0.0031 / 0.7729\n[0/1][208/938] Loss_D: 2.2130 Loss_G: 6.0916 D(x): 0.9951 D(G(z)): 0.8510 / 0.0064\n[0/1][209/938] Loss_D: 1.4920 Loss_G: 2.5609 D(x): 0.3866 D(G(z)): 0.0304 / 0.1386\n[0/1][210/938] Loss_D: 0.5268 Loss_G: 2.1543 D(x): 0.8163 D(G(z)): 0.2178 / 0.1610\n[0/1][211/938] Loss_D: 0.5517 Loss_G: 2.6482 D(x): 0.8291 D(G(z)): 0.2687 / 0.0985\n[0/1][212/938] Loss_D: 0.7115 Loss_G: 1.3515 D(x): 0.6818 D(G(z)): 0.2102 / 0.3006\n[0/1][213/938] Loss_D: 0.8340 Loss_G: 3.3682 D(x): 0.8447 D(G(z)): 0.4402 / 0.0487\n[0/1][214/938] Loss_D: 0.7118 Loss_G: 0.8892 D(x): 0.5772 D(G(z)): 0.0722 / 0.4497\n[0/1][215/938] Loss_D: 0.9638 Loss_G: 4.9697 D(x): 0.9554 D(G(z)): 0.5457 / 0.0097\n[0/1][216/938] Loss_D: 1.5767 Loss_G: 0.3857 D(x): 0.2895 D(G(z)): 0.0365 / 0.7129\n[0/1][217/938] Loss_D: 1.3846 Loss_G: 4.3821 D(x): 0.9752 D(G(z)): 0.6690 / 0.0212\n[0/1][218/938] Loss_D: 0.6745 Loss_G: 3.0223 D(x): 0.6469 D(G(z)): 0.0908 / 0.0800\n[0/1][219/938] Loss_D: 0.5624 Loss_G: 1.2342 D(x): 0.6975 D(G(z)): 0.1260 / 0.3395\n[0/1][220/938] Loss_D: 0.8105 Loss_G: 3.4985 D(x): 0.9242 D(G(z)): 0.4751 / 0.0482\n[0/1][221/938] Loss_D: 0.6743 Loss_G: 2.3752 D(x): 0.6695 D(G(z)): 0.1071 / 0.1206\n[0/1][222/938] Loss_D: 0.6577 Loss_G: 2.9396 D(x): 0.7830 D(G(z)): 0.2975 / 0.0736\n[0/1][223/938] Loss_D: 0.3707 Loss_G: 3.1916 D(x): 0.8297 D(G(z)): 0.1116 / 0.0703\n[0/1][224/938] Loss_D: 0.3440 Loss_G: 2.6964 D(x): 0.8538 D(G(z)): 0.1280 / 0.0896\n[0/1][225/938] Loss_D: 0.4961 Loss_G: 3.1652 D(x): 0.8790 D(G(z)): 0.2712 / 0.0590\n[0/1][226/938] Loss_D: 0.4380 Loss_G: 2.6713 D(x): 0.7946 D(G(z)): 0.1420 / 0.0972\n[0/1][227/938] Loss_D: 0.3170 Loss_G: 2.5697 D(x): 0.8489 D(G(z)): 0.1280 / 0.0970\n[0/1][228/938] Loss_D: 0.4348 Loss_G: 3.4805 D(x): 0.8796 D(G(z)): 0.2261 / 0.0470\n[0/1][229/938] Loss_D: 0.3619 Loss_G: 2.4489 D(x): 0.7724 D(G(z)): 0.0761 / 0.1162\n[0/1][230/938] Loss_D: 0.3905 Loss_G: 3.3544 D(x): 0.9050 D(G(z)): 0.2346 / 0.0445\n[0/1][231/938] Loss_D: 0.3203 Loss_G: 2.5127 D(x): 0.7941 D(G(z)): 0.0697 / 0.1025\n[0/1][232/938] Loss_D: 0.3564 Loss_G: 3.5867 D(x): 0.9166 D(G(z)): 0.2193 / 0.0365\n[0/1][233/938] Loss_D: 0.2902 Loss_G: 2.9255 D(x): 0.8198 D(G(z)): 0.0699 / 0.0815\n[0/1][234/938] Loss_D: 0.3356 Loss_G: 3.2739 D(x): 0.9093 D(G(z)): 0.1817 / 0.0530\n[0/1][235/938] Loss_D: 0.5151 Loss_G: 1.4674 D(x): 0.7216 D(G(z)): 0.1048 / 0.2882\n[0/1][236/938] Loss_D: 0.6315 Loss_G: 5.1678 D(x): 0.9369 D(G(z)): 0.3946 / 0.0094\n[0/1][237/938] Loss_D: 0.8377 Loss_G: 1.4724 D(x): 0.5099 D(G(z)): 0.0222 / 0.3047\n[0/1][238/938] Loss_D: 0.8353 Loss_G: 4.5666 D(x): 0.9701 D(G(z)): 0.4779 / 0.0169\n[0/1][239/938] Loss_D: 0.7250 Loss_G: 1.6636 D(x): 0.5729 D(G(z)): 0.0519 / 0.2552\n[0/1][240/938] Loss_D: 0.3882 Loss_G: 3.4189 D(x): 0.9616 D(G(z)): 0.2562 / 0.0530\n[0/1][241/938] Loss_D: 0.3353 Loss_G: 3.1499 D(x): 0.8601 D(G(z)): 0.1416 / 0.0614\n[0/1][242/938] Loss_D: 0.3377 Loss_G: 2.5114 D(x): 0.8128 D(G(z)): 0.0984 / 0.1198\n[0/1][243/938] Loss_D: 0.3964 Loss_G: 3.9936 D(x): 0.9195 D(G(z)): 0.2483 / 0.0260\n[0/1][244/938] Loss_D: 0.4026 Loss_G: 2.3654 D(x): 0.7685 D(G(z)): 0.0673 / 0.1188\n[0/1][245/938] Loss_D: 0.3590 Loss_G: 3.3170 D(x): 0.9053 D(G(z)): 0.1776 / 0.0495\n[0/1][246/938] Loss_D: 0.3814 Loss_G: 2.4324 D(x): 0.8183 D(G(z)): 0.1403 / 0.1162\n[0/1][247/938] Loss_D: 0.3335 Loss_G: 4.1700 D(x): 0.9167 D(G(z)): 0.2024 / 0.0216\n[0/1][248/938] Loss_D: 0.3678 Loss_G: 2.2415 D(x): 0.7743 D(G(z)): 0.0821 / 0.1490\n[0/1][249/938] Loss_D: 0.3702 Loss_G: 3.5827 D(x): 0.8998 D(G(z)): 0.2101 / 0.0376\n[0/1][250/938] Loss_D: 0.3007 Loss_G: 2.2829 D(x): 0.8112 D(G(z)): 0.0613 / 0.1345\n[0/1][251/938] Loss_D: 0.3377 Loss_G: 4.0197 D(x): 0.9371 D(G(z)): 0.2060 / 0.0291\n[0/1][252/938] Loss_D: 0.4078 Loss_G: 2.6532 D(x): 0.7540 D(G(z)): 0.0644 / 0.0948\n[0/1][253/938] Loss_D: 0.2699 Loss_G: 2.4460 D(x): 0.8856 D(G(z)): 0.1249 / 0.1082\n[0/1][254/938] Loss_D: 0.5477 Loss_G: 4.0125 D(x): 0.8500 D(G(z)): 0.2863 / 0.0226\n[0/1][255/938] Loss_D: 1.1233 Loss_G: 2.7869 D(x): 0.3924 D(G(z)): 0.0523 / 0.1171\n[0/1][256/938] Loss_D: 2.7099 Loss_G: 19.5397 D(x): 0.8694 D(G(z)): 0.8001 / 0.0000\n[0/1][257/938] Loss_D: 19.5501 Loss_G: 2.7812 D(x): 0.0000 D(G(z)): 0.0000 / 0.2694\n[0/1][258/938] Loss_D: 2.0463 Loss_G: 3.5478 D(x): 0.8099 D(G(z)): 0.5746 / 0.0851\n[0/1][259/938] Loss_D: 3.7303 Loss_G: 13.4688 D(x): 0.8166 D(G(z)): 0.8917 / 0.0000\n[0/1][260/938] Loss_D: 11.9989 Loss_G: 3.9393 D(x): 0.0001 D(G(z)): 0.0002 / 0.0810\n[0/1][261/938] Loss_D: 3.8238 Loss_G: 0.0007 D(x): 0.0860 D(G(z)): 0.1278 / 0.9993\n[0/1][262/938] Loss_D: 8.7992 Loss_G: 0.5445 D(x): 0.9989 D(G(z)): 0.9994 / 0.6524\n[0/1][263/938] Loss_D: 1.7549 Loss_G: 8.7473 D(x): 0.8789 D(G(z)): 0.6926 / 0.0007\n[0/1][264/938] Loss_D: 4.2527 Loss_G: 4.1074 D(x): 0.0556 D(G(z)): 0.0048 / 0.0822\n[0/1][265/938] Loss_D: 2.4627 Loss_G: 0.1400 D(x): 0.3629 D(G(z)): 0.3165 / 0.8837\n[0/1][266/938] Loss_D: 3.9331 Loss_G: 2.3569 D(x): 0.8869 D(G(z)): 0.9281 / 0.1837\n[0/1][267/938] Loss_D: 2.2788 Loss_G: 1.7092 D(x): 0.3049 D(G(z)): 0.2740 / 0.2549\n[0/1][268/938] Loss_D: 1.3092 Loss_G: 0.8037 D(x): 0.5190 D(G(z)): 0.3489 / 0.4741\n[0/1][269/938] Loss_D: 1.1872 Loss_G: 2.7118 D(x): 0.7541 D(G(z)): 0.5260 / 0.0900\n[0/1][270/938] Loss_D: 0.9367 Loss_G: 1.8271 D(x): 0.5658 D(G(z)): 0.2261 / 0.1996\n[0/1][271/938] Loss_D: 0.9251 Loss_G: 1.3619 D(x): 0.6558 D(G(z)): 0.3283 / 0.3050\n[0/1][272/938] Loss_D: 1.4107 Loss_G: 2.1304 D(x): 0.6981 D(G(z)): 0.5783 / 0.1582\n[0/1][273/938] Loss_D: 1.7386 Loss_G: 1.3378 D(x): 0.4351 D(G(z)): 0.4476 / 0.3605\n[0/1][274/938] Loss_D: 2.2719 Loss_G: 1.0153 D(x): 0.4172 D(G(z)): 0.6327 / 0.4458\n[0/1][275/938] Loss_D: 2.3930 Loss_G: 1.5369 D(x): 0.4398 D(G(z)): 0.6716 / 0.3137\n[0/1][276/938] Loss_D: 1.7300 Loss_G: 1.3903 D(x): 0.3861 D(G(z)): 0.4094 / 0.3380\n[0/1][277/938] Loss_D: 1.4012 Loss_G: 2.0841 D(x): 0.6427 D(G(z)): 0.4795 / 0.1952\n[0/1][278/938] Loss_D: 1.0536 Loss_G: 2.2928 D(x): 0.6437 D(G(z)): 0.3791 / 0.1403\n[0/1][279/938] Loss_D: 1.2816 Loss_G: 1.7066 D(x): 0.5558 D(G(z)): 0.3989 / 0.2435\n[0/1][280/938] Loss_D: 1.4279 Loss_G: 1.5097 D(x): 0.5349 D(G(z)): 0.4711 / 0.2734\n[0/1][281/938] Loss_D: 1.4900 Loss_G: 1.2784 D(x): 0.4909 D(G(z)): 0.4672 / 0.3154\n[0/1][282/938] Loss_D: 1.5298 Loss_G: 1.2275 D(x): 0.4993 D(G(z)): 0.4998 / 0.3230\n[0/1][283/938] Loss_D: 1.3083 Loss_G: 1.2336 D(x): 0.5185 D(G(z)): 0.4092 / 0.3303\n[0/1][284/938] Loss_D: 1.2811 Loss_G: 2.2243 D(x): 0.6314 D(G(z)): 0.4798 / 0.1447\n[0/1][285/938] Loss_D: 1.2899 Loss_G: 0.7637 D(x): 0.4642 D(G(z)): 0.2392 / 0.4989\n[0/1][286/938] Loss_D: 1.3563 Loss_G: 3.4326 D(x): 0.8166 D(G(z)): 0.6225 / 0.0547\n[0/1][287/938] Loss_D: 1.6142 Loss_G: 0.7346 D(x): 0.3261 D(G(z)): 0.1706 / 0.5289\n[0/1][288/938] Loss_D: 1.8088 Loss_G: 2.8153 D(x): 0.8082 D(G(z)): 0.7110 / 0.0892\n[0/1][289/938] Loss_D: 1.5920 Loss_G: 1.0093 D(x): 0.3511 D(G(z)): 0.2723 / 0.3983\n[0/1][290/938] Loss_D: 1.8048 Loss_G: 1.2580 D(x): 0.5209 D(G(z)): 0.6042 / 0.3264\n[0/1][291/938] Loss_D: 1.6631 Loss_G: 1.6041 D(x): 0.4916 D(G(z)): 0.5197 / 0.2280\n[0/1][292/938] Loss_D: 1.4678 Loss_G: 0.8502 D(x): 0.4291 D(G(z)): 0.3579 / 0.4617\n[0/1][293/938] Loss_D: 1.1718 Loss_G: 2.6709 D(x): 0.7515 D(G(z)): 0.5454 / 0.0851\n[0/1][294/938] Loss_D: 1.0438 Loss_G: 1.3321 D(x): 0.5034 D(G(z)): 0.1846 / 0.3193\n[0/1][295/938] Loss_D: 0.9911 Loss_G: 1.9119 D(x): 0.7489 D(G(z)): 0.4373 / 0.1978\n[0/1][296/938] Loss_D: 1.2510 Loss_G: 1.6791 D(x): 0.5732 D(G(z)): 0.3988 / 0.2275\n[0/1][297/938] Loss_D: 1.3365 Loss_G: 1.9482 D(x): 0.6178 D(G(z)): 0.4732 / 0.1956\n[0/1][298/938] Loss_D: 1.6187 Loss_G: 0.6755 D(x): 0.3883 D(G(z)): 0.3171 / 0.5444\n[0/1][299/938] Loss_D: 1.4342 Loss_G: 2.7630 D(x): 0.7839 D(G(z)): 0.6416 / 0.0902\n[0/1][300/938] Loss_D: 1.6910 Loss_G: 0.8565 D(x): 0.3376 D(G(z)): 0.2330 / 0.4754\n[0/1][301/938] Loss_D: 1.4642 Loss_G: 1.9833 D(x): 0.7264 D(G(z)): 0.5820 / 0.1738\n[0/1][302/938] Loss_D: 1.1101 Loss_G: 1.5002 D(x): 0.5539 D(G(z)): 0.2951 / 0.2630\n[0/1][303/938] Loss_D: 1.0541 Loss_G: 1.7986 D(x): 0.6589 D(G(z)): 0.4073 / 0.1890\n[0/1][304/938] Loss_D: 1.1062 Loss_G: 1.6240 D(x): 0.6038 D(G(z)): 0.3855 / 0.2303\n[0/1][305/938] Loss_D: 1.1175 Loss_G: 1.7659 D(x): 0.6495 D(G(z)): 0.4106 / 0.2122\n[0/1][306/938] Loss_D: 1.4494 Loss_G: 1.4152 D(x): 0.5238 D(G(z)): 0.4449 / 0.2872\n[0/1][307/938] Loss_D: 1.5852 Loss_G: 1.6526 D(x): 0.5083 D(G(z)): 0.5094 / 0.2335\n[0/1][308/938] Loss_D: 1.1825 Loss_G: 0.9426 D(x): 0.4888 D(G(z)): 0.3059 / 0.4350\n[0/1][309/938] Loss_D: 1.2394 Loss_G: 3.6181 D(x): 0.7706 D(G(z)): 0.5863 / 0.0334\n[0/1][310/938] Loss_D: 1.5088 Loss_G: 0.4840 D(x): 0.2898 D(G(z)): 0.0758 / 0.6451\n[0/1][311/938] Loss_D: 1.7258 Loss_G: 3.5464 D(x): 0.9066 D(G(z)): 0.7523 / 0.0501\n[0/1][312/938] Loss_D: 1.4121 Loss_G: 1.0152 D(x): 0.3610 D(G(z)): 0.1095 / 0.4203\n[0/1][313/938] Loss_D: 1.6383 Loss_G: 2.2858 D(x): 0.8045 D(G(z)): 0.6790 / 0.1444\n[0/1][314/938] Loss_D: 1.6835 Loss_G: 0.8670 D(x): 0.3535 D(G(z)): 0.3119 / 0.4647\n[0/1][315/938] Loss_D: 1.5420 Loss_G: 1.6329 D(x): 0.6066 D(G(z)): 0.5878 / 0.2284\n[0/1][316/938] Loss_D: 1.3177 Loss_G: 1.0473 D(x): 0.4684 D(G(z)): 0.3398 / 0.3833\n[0/1][317/938] Loss_D: 0.9815 Loss_G: 1.7590 D(x): 0.6779 D(G(z)): 0.4024 / 0.1989\n[0/1][318/938] Loss_D: 0.8869 Loss_G: 1.9219 D(x): 0.6657 D(G(z)): 0.3387 / 0.1702\n[0/1][319/938] Loss_D: 0.7934 Loss_G: 1.5478 D(x): 0.6698 D(G(z)): 0.2819 / 0.2539\n[0/1][320/938] Loss_D: 0.9813 Loss_G: 2.0192 D(x): 0.7277 D(G(z)): 0.4366 / 0.1644\n[0/1][321/938] Loss_D: 1.2659 Loss_G: 0.9964 D(x): 0.4917 D(G(z)): 0.3477 / 0.4125\n[0/1][322/938] Loss_D: 1.3270 Loss_G: 1.7089 D(x): 0.6374 D(G(z)): 0.5280 / 0.2095\n[0/1][323/938] Loss_D: 1.1425 Loss_G: 1.0355 D(x): 0.4975 D(G(z)): 0.2983 / 0.3807\n[0/1][324/938] Loss_D: 1.1310 Loss_G: 1.5211 D(x): 0.6441 D(G(z)): 0.4521 / 0.2462\n[0/1][325/938] Loss_D: 0.9529 Loss_G: 1.9183 D(x): 0.6597 D(G(z)): 0.3698 / 0.1727\n[0/1][326/938] Loss_D: 0.8574 Loss_G: 1.1987 D(x): 0.5879 D(G(z)): 0.2324 / 0.3650\n[0/1][327/938] Loss_D: 1.1094 Loss_G: 2.8457 D(x): 0.7905 D(G(z)): 0.5273 / 0.0799\n[0/1][328/938] Loss_D: 1.2648 Loss_G: 0.7187 D(x): 0.3904 D(G(z)): 0.1674 / 0.5363\n[0/1][329/938] Loss_D: 1.3896 Loss_G: 2.9438 D(x): 0.8660 D(G(z)): 0.6355 / 0.0723\n[0/1][330/938] Loss_D: 1.3307 Loss_G: 0.8456 D(x): 0.3672 D(G(z)): 0.1137 / 0.4935\n[0/1][331/938] Loss_D: 1.3266 Loss_G: 2.4708 D(x): 0.8660 D(G(z)): 0.6307 / 0.1122\n[0/1][332/938] Loss_D: 0.9863 Loss_G: 1.3993 D(x): 0.5090 D(G(z)): 0.1843 / 0.2807\n[0/1][333/938] Loss_D: 0.9041 Loss_G: 1.8523 D(x): 0.7158 D(G(z)): 0.3863 / 0.1878\n[0/1][334/938] Loss_D: 0.9538 Loss_G: 1.6756 D(x): 0.6327 D(G(z)): 0.3293 / 0.2321\n[0/1][335/938] Loss_D: 1.0459 Loss_G: 1.8741 D(x): 0.6402 D(G(z)): 0.3779 / 0.1848\n[0/1][336/938] Loss_D: 0.9736 Loss_G: 1.3174 D(x): 0.5976 D(G(z)): 0.2973 / 0.3088\n[0/1][337/938] Loss_D: 1.0499 Loss_G: 2.4622 D(x): 0.7370 D(G(z)): 0.4613 / 0.1125\n[0/1][338/938] Loss_D: 1.4207 Loss_G: 0.3807 D(x): 0.3831 D(G(z)): 0.2002 / 0.7150\n[0/1][339/938] Loss_D: 1.9889 Loss_G: 4.1014 D(x): 0.8874 D(G(z)): 0.8143 / 0.0296\n[0/1][340/938] Loss_D: 2.5272 Loss_G: 0.5382 D(x): 0.1140 D(G(z)): 0.0478 / 0.6423\n[0/1][341/938] Loss_D: 1.7784 Loss_G: 1.8387 D(x): 0.8207 D(G(z)): 0.6668 / 0.2069\n[0/1][342/938] Loss_D: 1.0803 Loss_G: 1.2656 D(x): 0.5204 D(G(z)): 0.2850 / 0.3285\n[0/1][343/938] Loss_D: 0.9470 Loss_G: 1.8658 D(x): 0.7243 D(G(z)): 0.4090 / 0.1857\n[0/1][344/938] Loss_D: 0.8394 Loss_G: 1.3831 D(x): 0.5979 D(G(z)): 0.2176 / 0.2982\n[0/1][345/938] Loss_D: 0.9699 Loss_G: 1.8838 D(x): 0.7415 D(G(z)): 0.4171 / 0.1815\n[0/1][346/938] Loss_D: 0.8839 Loss_G: 1.3638 D(x): 0.6175 D(G(z)): 0.2802 / 0.2882\n[0/1][347/938] Loss_D: 0.9248 Loss_G: 1.7253 D(x): 0.6976 D(G(z)): 0.3963 / 0.2068\n[0/1][348/938] Loss_D: 0.8427 Loss_G: 1.4966 D(x): 0.6378 D(G(z)): 0.2748 / 0.2707\n[0/1][349/938] Loss_D: 0.8662 Loss_G: 1.5798 D(x): 0.6872 D(G(z)): 0.3469 / 0.2339\n[0/1][350/938] Loss_D: 0.8959 Loss_G: 2.8683 D(x): 0.7429 D(G(z)): 0.4080 / 0.0809\n[0/1][351/938] Loss_D: 1.1874 Loss_G: 0.6217 D(x): 0.3978 D(G(z)): 0.1237 / 0.5978\n[0/1][352/938] Loss_D: 1.2888 Loss_G: 3.5548 D(x): 0.9405 D(G(z)): 0.6374 / 0.0527\n[0/1][353/938] Loss_D: 0.7829 Loss_G: 2.4191 D(x): 0.5832 D(G(z)): 0.1305 / 0.1381\n[0/1][354/938] Loss_D: 0.7744 Loss_G: 1.2646 D(x): 0.6526 D(G(z)): 0.2230 / 0.3513\n[0/1][355/938] Loss_D: 1.0333 Loss_G: 3.4502 D(x): 0.8842 D(G(z)): 0.5459 / 0.0416\n[0/1][356/938] Loss_D: 1.4749 Loss_G: 0.7554 D(x): 0.3483 D(G(z)): 0.1498 / 0.5178\n[0/1][357/938] Loss_D: 1.5571 Loss_G: 3.0658 D(x): 0.8420 D(G(z)): 0.6914 / 0.0668\n[0/1][358/938] Loss_D: 1.3614 Loss_G: 0.7831 D(x): 0.3421 D(G(z)): 0.0946 / 0.5131\n[0/1][359/938] Loss_D: 1.3521 Loss_G: 2.4200 D(x): 0.8362 D(G(z)): 0.6153 / 0.1328\n[0/1][360/938] Loss_D: 0.9441 Loss_G: 1.5527 D(x): 0.5392 D(G(z)): 0.1752 / 0.2675\n[0/1][361/938] Loss_D: 0.8974 Loss_G: 2.0307 D(x): 0.7659 D(G(z)): 0.4066 / 0.1618\n[0/1][362/938] Loss_D: 0.8149 Loss_G: 1.4796 D(x): 0.6190 D(G(z)): 0.2468 / 0.2685\n[0/1][363/938] Loss_D: 0.8712 Loss_G: 3.1376 D(x): 0.7919 D(G(z)): 0.4339 / 0.0571\n[0/1][364/938] Loss_D: 1.0845 Loss_G: 0.7744 D(x): 0.4628 D(G(z)): 0.1548 / 0.5196\n[0/1][365/938] Loss_D: 1.5115 Loss_G: 3.1969 D(x): 0.8285 D(G(z)): 0.6419 / 0.0597\n[0/1][366/938] Loss_D: 1.2107 Loss_G: 0.8967 D(x): 0.3985 D(G(z)): 0.0775 / 0.4671\n[0/1][367/938] Loss_D: 1.2626 Loss_G: 3.0262 D(x): 0.8682 D(G(z)): 0.6154 / 0.0758\n[0/1][368/938] Loss_D: 1.0756 Loss_G: 1.1663 D(x): 0.4707 D(G(z)): 0.1350 / 0.3676\n[0/1][369/938] Loss_D: 1.0249 Loss_G: 2.7673 D(x): 0.8393 D(G(z)): 0.5078 / 0.0951\n[0/1][370/938] Loss_D: 0.9620 Loss_G: 1.1491 D(x): 0.5091 D(G(z)): 0.1386 / 0.3793\n[0/1][371/938] Loss_D: 1.0309 Loss_G: 2.3464 D(x): 0.8065 D(G(z)): 0.5076 / 0.1153\n[0/1][372/938] Loss_D: 0.9326 Loss_G: 1.2740 D(x): 0.5647 D(G(z)): 0.2364 / 0.3202\n[0/1][373/938] Loss_D: 0.7585 Loss_G: 1.7787 D(x): 0.7422 D(G(z)): 0.3186 / 0.2107\n[0/1][374/938] Loss_D: 0.9039 Loss_G: 2.3920 D(x): 0.7500 D(G(z)): 0.4139 / 0.1170\n[0/1][375/938] Loss_D: 1.0602 Loss_G: 0.7408 D(x): 0.4619 D(G(z)): 0.1401 / 0.5219\n[0/1][376/938] Loss_D: 1.1920 Loss_G: 3.4048 D(x): 0.8988 D(G(z)): 0.6041 / 0.0438\n[0/1][377/938] Loss_D: 1.1668 Loss_G: 0.8848 D(x): 0.3972 D(G(z)): 0.1063 / 0.4572\n[0/1][378/938] Loss_D: 1.0048 Loss_G: 2.7232 D(x): 0.8515 D(G(z)): 0.5109 / 0.0985\n[0/1][379/938] Loss_D: 0.9655 Loss_G: 1.4747 D(x): 0.5555 D(G(z)): 0.2080 / 0.2821\n[0/1][380/938] Loss_D: 0.8302 Loss_G: 1.9967 D(x): 0.7490 D(G(z)): 0.3721 / 0.1670\n[0/1][381/938] Loss_D: 0.8058 Loss_G: 1.9767 D(x): 0.6854 D(G(z)): 0.2936 / 0.1736\n[0/1][382/938] Loss_D: 0.8167 Loss_G: 1.4770 D(x): 0.6673 D(G(z)): 0.2765 / 0.2723\n[0/1][383/938] Loss_D: 0.8358 Loss_G: 3.1559 D(x): 0.8125 D(G(z)): 0.4279 / 0.0555\n[0/1][384/938] Loss_D: 1.2364 Loss_G: 0.3724 D(x): 0.3750 D(G(z)): 0.0553 / 0.7205\n[0/1][385/938] Loss_D: 1.8796 Loss_G: 4.0596 D(x): 0.9667 D(G(z)): 0.7960 / 0.0254\n[0/1][386/938] Loss_D: 1.1613 Loss_G: 1.7096 D(x): 0.3848 D(G(z)): 0.0436 / 0.2401\n[0/1][387/938] Loss_D: 0.9608 Loss_G: 1.1876 D(x): 0.7096 D(G(z)): 0.3729 / 0.3529\n[0/1][388/938] Loss_D: 1.1253 Loss_G: 3.1922 D(x): 0.8234 D(G(z)): 0.5493 / 0.0577\n[0/1][389/938] Loss_D: 1.3266 Loss_G: 0.6586 D(x): 0.3415 D(G(z)): 0.0949 / 0.5427\n[0/1][390/938] Loss_D: 0.9929 Loss_G: 2.7140 D(x): 0.9160 D(G(z)): 0.5384 / 0.0891\n[0/1][391/938] Loss_D: 0.7720 Loss_G: 1.7884 D(x): 0.6152 D(G(z)): 0.1895 / 0.2089\n[0/1][392/938] Loss_D: 0.7784 Loss_G: 2.3928 D(x): 0.7699 D(G(z)): 0.3493 / 0.1216\n[0/1][393/938] Loss_D: 0.8529 Loss_G: 1.4565 D(x): 0.6318 D(G(z)): 0.2462 / 0.2943\n[0/1][394/938] Loss_D: 0.9689 Loss_G: 2.5739 D(x): 0.7474 D(G(z)): 0.4234 / 0.0890\n[0/1][395/938] Loss_D: 0.8948 Loss_G: 1.3385 D(x): 0.5727 D(G(z)): 0.2066 / 0.3038\n[0/1][396/938] Loss_D: 0.7941 Loss_G: 2.9775 D(x): 0.8266 D(G(z)): 0.4074 / 0.0683\n[0/1][397/938] Loss_D: 0.8062 Loss_G: 1.0800 D(x): 0.5561 D(G(z)): 0.1093 / 0.4062\n[0/1][398/938] Loss_D: 1.0604 Loss_G: 4.0415 D(x): 0.9394 D(G(z)): 0.5796 / 0.0230\n[0/1][399/938] Loss_D: 1.4347 Loss_G: 0.6507 D(x): 0.3121 D(G(z)): 0.0682 / 0.5764\n[0/1][400/938] Loss_D: 1.2280 Loss_G: 3.6884 D(x): 0.9376 D(G(z)): 0.6182 / 0.0436\n[0/1][401/938] Loss_D: 1.3812 Loss_G: 0.9573 D(x): 0.3696 D(G(z)): 0.1102 / 0.4893\n[0/1][402/938] Loss_D: 1.2677 Loss_G: 3.0459 D(x): 0.8772 D(G(z)): 0.5517 / 0.0775\n[0/1][403/938] Loss_D: 1.3421 Loss_G: 0.9068 D(x): 0.4284 D(G(z)): 0.1725 / 0.4432\n[0/1][404/938] Loss_D: 1.1566 Loss_G: 3.1172 D(x): 0.9084 D(G(z)): 0.5828 / 0.0603\n[0/1][405/938] Loss_D: 0.8698 Loss_G: 1.7310 D(x): 0.5321 D(G(z)): 0.1152 / 0.2317\n[0/1][406/938] Loss_D: 0.9589 Loss_G: 1.9656 D(x): 0.7515 D(G(z)): 0.3969 / 0.1777\n[0/1][407/938] Loss_D: 0.8918 Loss_G: 2.3860 D(x): 0.6859 D(G(z)): 0.3418 / 0.1344\n[0/1][408/938] Loss_D: 0.8773 Loss_G: 0.8389 D(x): 0.5552 D(G(z)): 0.1775 / 0.4819\n[0/1][409/938] Loss_D: 1.1458 Loss_G: 4.2261 D(x): 0.9339 D(G(z)): 0.5981 / 0.0202\n[0/1][410/938] Loss_D: 1.3893 Loss_G: 0.6761 D(x): 0.3116 D(G(z)): 0.0499 / 0.5574\n[0/1][411/938] Loss_D: 1.3141 Loss_G: 3.4089 D(x): 0.9442 D(G(z)): 0.6655 / 0.0492\n[0/1][412/938] Loss_D: 1.0433 Loss_G: 1.3687 D(x): 0.4559 D(G(z)): 0.1063 / 0.3218\n[0/1][413/938] Loss_D: 0.9401 Loss_G: 1.8069 D(x): 0.7683 D(G(z)): 0.4223 / 0.1967\n[0/1][414/938] Loss_D: 0.8040 Loss_G: 2.1984 D(x): 0.7156 D(G(z)): 0.3222 / 0.1347\n[0/1][415/938] Loss_D: 0.9097 Loss_G: 1.3331 D(x): 0.5895 D(G(z)): 0.2242 / 0.3043\n[0/1][416/938] Loss_D: 0.8474 Loss_G: 2.3126 D(x): 0.7724 D(G(z)): 0.3856 / 0.1324\n[0/1][417/938] Loss_D: 0.7724 Loss_G: 1.5207 D(x): 0.6453 D(G(z)): 0.2153 / 0.2592\n[0/1][418/938] Loss_D: 0.7174 Loss_G: 3.2163 D(x): 0.8591 D(G(z)): 0.3861 / 0.0544\n[0/1][419/938] Loss_D: 1.0422 Loss_G: 1.0156 D(x): 0.4922 D(G(z)): 0.1424 / 0.4133\n[0/1][420/938] Loss_D: 0.8554 Loss_G: 3.2967 D(x): 0.8692 D(G(z)): 0.4658 / 0.0464\n[0/1][421/938] Loss_D: 1.2117 Loss_G: 0.3531 D(x): 0.3795 D(G(z)): 0.0953 / 0.7259\n[0/1][422/938] Loss_D: 1.6564 Loss_G: 3.5503 D(x): 0.9563 D(G(z)): 0.7528 / 0.0409\n[0/1][423/938] Loss_D: 1.5348 Loss_G: 0.9223 D(x): 0.3050 D(G(z)): 0.0927 / 0.4427\n[0/1][424/938] Loss_D: 0.8445 Loss_G: 2.0716 D(x): 0.8629 D(G(z)): 0.4631 / 0.1507\n[0/1][425/938] Loss_D: 0.8153 Loss_G: 2.6170 D(x): 0.7457 D(G(z)): 0.3482 / 0.0918\n[0/1][426/938] Loss_D: 0.7754 Loss_G: 1.1550 D(x): 0.5694 D(G(z)): 0.1300 / 0.3680\n[0/1][427/938] Loss_D: 0.9889 Loss_G: 2.7910 D(x): 0.8582 D(G(z)): 0.4927 / 0.0874\n[0/1][428/938] Loss_D: 0.7243 Loss_G: 1.4436 D(x): 0.6019 D(G(z)): 0.1266 / 0.2836\n[0/1][429/938] Loss_D: 0.8722 Loss_G: 2.7980 D(x): 0.8190 D(G(z)): 0.4388 / 0.0799\n[0/1][430/938] Loss_D: 0.6421 Loss_G: 1.6410 D(x): 0.6335 D(G(z)): 0.1310 / 0.2378\n[0/1][431/938] Loss_D: 0.6480 Loss_G: 2.7355 D(x): 0.8523 D(G(z)): 0.3544 / 0.0791\n[0/1][432/938] Loss_D: 0.7529 Loss_G: 1.2219 D(x): 0.5977 D(G(z)): 0.1518 / 0.3618\n[0/1][433/938] Loss_D: 0.8531 Loss_G: 3.3519 D(x): 0.8801 D(G(z)): 0.4616 / 0.0547\n[0/1][434/938] Loss_D: 1.0055 Loss_G: 0.9773 D(x): 0.5112 D(G(z)): 0.1107 / 0.4440\n[0/1][435/938] Loss_D: 1.1007 Loss_G: 3.7023 D(x): 0.9101 D(G(z)): 0.5683 / 0.0336\n[0/1][436/938] Loss_D: 1.0621 Loss_G: 1.1636 D(x): 0.4527 D(G(z)): 0.0741 / 0.3967\n[0/1][437/938] Loss_D: 0.9586 Loss_G: 2.5353 D(x): 0.8492 D(G(z)): 0.4659 / 0.1085\n[0/1][438/938] Loss_D: 0.7152 Loss_G: 1.8452 D(x): 0.6492 D(G(z)): 0.1865 / 0.2101\n[0/1][439/938] Loss_D: 0.5855 Loss_G: 2.3365 D(x): 0.7872 D(G(z)): 0.2508 / 0.1249\n[0/1][440/938] Loss_D: 0.6441 Loss_G: 2.0522 D(x): 0.7691 D(G(z)): 0.2827 / 0.1509\n[0/1][441/938] Loss_D: 0.5995 Loss_G: 2.4788 D(x): 0.7491 D(G(z)): 0.2397 / 0.0993\n[0/1][442/938] Loss_D: 0.6678 Loss_G: 1.1955 D(x): 0.6717 D(G(z)): 0.1800 / 0.3477\n[0/1][443/938] Loss_D: 0.8594 Loss_G: 4.6306 D(x): 0.9040 D(G(z)): 0.4857 / 0.0135\n[0/1][444/938] Loss_D: 1.9728 Loss_G: 1.0228 D(x): 0.2223 D(G(z)): 0.0431 / 0.4338\n[0/1][445/938] Loss_D: 1.1018 Loss_G: 3.9993 D(x): 0.8855 D(G(z)): 0.5425 / 0.0443\n[0/1][446/938] Loss_D: 2.0152 Loss_G: 0.1040 D(x): 0.2341 D(G(z)): 0.0892 / 0.9100\n[0/1][447/938] Loss_D: 3.2483 Loss_G: 3.7767 D(x): 0.9600 D(G(z)): 0.9203 / 0.0432\n[0/1][448/938] Loss_D: 2.5748 Loss_G: 0.3422 D(x): 0.1124 D(G(z)): 0.0755 / 0.7416\n[0/1][449/938] Loss_D: 1.6075 Loss_G: 2.3425 D(x): 0.8738 D(G(z)): 0.6784 / 0.1379\n[0/1][450/938] Loss_D: 1.4645 Loss_G: 1.4768 D(x): 0.4727 D(G(z)): 0.3563 / 0.2788\n[0/1][451/938] Loss_D: 1.1727 Loss_G: 1.2014 D(x): 0.5698 D(G(z)): 0.3530 / 0.3721\n[0/1][452/938] Loss_D: 1.1967 Loss_G: 2.0992 D(x): 0.7336 D(G(z)): 0.4943 / 0.1797\n[0/1][453/938] Loss_D: 1.1601 Loss_G: 0.9014 D(x): 0.5080 D(G(z)): 0.2457 / 0.4493\n[0/1][454/938] Loss_D: 1.2393 Loss_G: 2.4245 D(x): 0.7989 D(G(z)): 0.5781 / 0.1241\n[0/1][455/938] Loss_D: 1.0286 Loss_G: 1.3022 D(x): 0.5153 D(G(z)): 0.2058 / 0.3492\n[0/1][456/938] Loss_D: 0.8999 Loss_G: 1.5783 D(x): 0.7250 D(G(z)): 0.3709 / 0.2573\n[0/1][457/938] Loss_D: 0.9581 Loss_G: 2.5452 D(x): 0.7436 D(G(z)): 0.4236 / 0.1062\n[0/1][458/938] Loss_D: 0.9523 Loss_G: 0.9031 D(x): 0.5329 D(G(z)): 0.1715 / 0.4446\n[0/1][459/938] Loss_D: 1.0237 Loss_G: 3.2954 D(x): 0.8706 D(G(z)): 0.5398 / 0.0510\n[0/1][460/938] Loss_D: 1.4970 Loss_G: 0.3243 D(x): 0.3028 D(G(z)): 0.0925 / 0.7450\n[0/1][461/938] Loss_D: 1.6696 Loss_G: 5.0739 D(x): 0.9530 D(G(z)): 0.7415 / 0.0130\n[0/1][462/938] Loss_D: 2.7998 Loss_G: 0.2547 D(x): 0.1249 D(G(z)): 0.0415 / 0.8054\n[0/1][463/938] Loss_D: 2.2668 Loss_G: 4.3910 D(x): 0.9749 D(G(z)): 0.8399 / 0.0211\n[0/1][464/938] Loss_D: 2.2570 Loss_G: 0.9993 D(x): 0.1558 D(G(z)): 0.0468 / 0.4499\n[0/1][465/938] Loss_D: 1.2110 Loss_G: 1.0301 D(x): 0.7546 D(G(z)): 0.5179 / 0.4021\n[0/1][466/938] Loss_D: 1.5362 Loss_G: 1.9274 D(x): 0.6380 D(G(z)): 0.5938 / 0.1640\n[0/1][467/938] Loss_D: 1.6416 Loss_G: 0.5766 D(x): 0.3081 D(G(z)): 0.2652 / 0.5969\n[0/1][468/938] Loss_D: 1.6480 Loss_G: 1.6024 D(x): 0.7608 D(G(z)): 0.6857 / 0.2301\n[0/1][469/938] Loss_D: 1.3889 Loss_G: 0.9194 D(x): 0.4044 D(G(z)): 0.3038 / 0.4369\n[0/1][470/938] Loss_D: 1.4188 Loss_G: 1.5905 D(x): 0.6597 D(G(z)): 0.5462 / 0.2505\n[0/1][471/938] Loss_D: 1.2494 Loss_G: 1.2917 D(x): 0.5409 D(G(z)): 0.3779 / 0.3080\n[0/1][472/938] Loss_D: 1.1043 Loss_G: 1.3849 D(x): 0.6225 D(G(z)): 0.4253 / 0.2798\n[0/1][473/938] Loss_D: 1.1400 Loss_G: 1.5962 D(x): 0.6140 D(G(z)): 0.4230 / 0.2360\n[0/1][474/938] Loss_D: 1.0453 Loss_G: 1.2186 D(x): 0.5623 D(G(z)): 0.3297 / 0.3297\n[0/1][475/938] Loss_D: 1.1612 Loss_G: 1.6119 D(x): 0.6277 D(G(z)): 0.4356 / 0.2204\n[0/1][476/938] Loss_D: 1.1164 Loss_G: 0.8969 D(x): 0.5019 D(G(z)): 0.2918 / 0.4488\n[0/1][477/938] Loss_D: 1.1207 Loss_G: 2.3092 D(x): 0.7718 D(G(z)): 0.5314 / 0.1201\n[0/1][478/938] Loss_D: 1.1870 Loss_G: 0.9608 D(x): 0.4421 D(G(z)): 0.2299 / 0.4176\n[0/1][479/938] Loss_D: 1.0025 Loss_G: 1.8513 D(x): 0.7539 D(G(z)): 0.4688 / 0.1953\n[0/1][480/938] Loss_D: 0.8984 Loss_G: 1.3616 D(x): 0.5939 D(G(z)): 0.2502 / 0.3026\n[0/1][481/938] Loss_D: 0.8841 Loss_G: 1.7441 D(x): 0.7386 D(G(z)): 0.3865 / 0.2071\n[0/1][482/938] Loss_D: 0.9110 Loss_G: 1.6227 D(x): 0.6456 D(G(z)): 0.3224 / 0.2325\n[0/1][483/938] Loss_D: 0.9717 Loss_G: 1.0297 D(x): 0.5893 D(G(z)): 0.3146 / 0.3911\n[0/1][484/938] Loss_D: 1.1027 Loss_G: 2.2090 D(x): 0.7455 D(G(z)): 0.5166 / 0.1305\n[0/1][485/938] Loss_D: 1.1131 Loss_G: 0.6801 D(x): 0.4264 D(G(z)): 0.1517 / 0.5409\n[0/1][486/938] Loss_D: 1.4841 Loss_G: 2.8619 D(x): 0.8871 D(G(z)): 0.7014 / 0.0740\n[0/1][487/938] Loss_D: 1.4257 Loss_G: 0.7805 D(x): 0.3370 D(G(z)): 0.1419 / 0.5051\n[0/1][488/938] Loss_D: 1.0687 Loss_G: 2.2230 D(x): 0.8560 D(G(z)): 0.5348 / 0.1402\n[0/1][489/938] Loss_D: 0.9871 Loss_G: 1.2709 D(x): 0.5578 D(G(z)): 0.2213 / 0.3331\n[0/1][490/938] Loss_D: 0.9647 Loss_G: 2.1712 D(x): 0.7692 D(G(z)): 0.4406 / 0.1417\n[0/1][491/938] Loss_D: 0.9493 Loss_G: 1.3936 D(x): 0.5816 D(G(z)): 0.2571 / 0.2897\n[0/1][492/938] Loss_D: 1.0583 Loss_G: 2.2481 D(x): 0.6789 D(G(z)): 0.4355 / 0.1301\n[0/1][493/938] Loss_D: 1.0731 Loss_G: 0.6826 D(x): 0.4745 D(G(z)): 0.2049 / 0.5609\n[0/1][494/938] Loss_D: 1.2723 Loss_G: 3.5651 D(x): 0.8513 D(G(z)): 0.6214 / 0.0443\n[0/1][495/938] Loss_D: 1.5149 Loss_G: 0.5038 D(x): 0.2909 D(G(z)): 0.0751 / 0.6307\n[0/1][496/938] Loss_D: 1.4680 Loss_G: 2.7499 D(x): 0.8937 D(G(z)): 0.6952 / 0.0810\n[0/1][497/938] Loss_D: 1.0602 Loss_G: 1.3299 D(x): 0.4551 D(G(z)): 0.1273 / 0.3063\n[0/1][498/938] Loss_D: 0.8654 Loss_G: 2.2544 D(x): 0.8232 D(G(z)): 0.4512 / 0.1320\n[0/1][499/938] Loss_D: 1.0370 Loss_G: 1.2483 D(x): 0.5576 D(G(z)): 0.2740 / 0.3311\n[0/1][500/938] Loss_D: 0.7837 Loss_G: 1.6997 D(x): 0.7468 D(G(z)): 0.3590 / 0.2042\n[0/1][501/938] Loss_D: 0.8502 Loss_G: 1.8833 D(x): 0.6984 D(G(z)): 0.3358 / 0.1743\n[0/1][502/938] Loss_D: 0.8076 Loss_G: 1.5448 D(x): 0.6796 D(G(z)): 0.2793 / 0.2482\n[0/1][503/938] Loss_D: 0.8710 Loss_G: 1.8506 D(x): 0.7020 D(G(z)): 0.3638 / 0.1838\n[0/1][504/938] Loss_D: 0.8092 Loss_G: 1.8820 D(x): 0.6896 D(G(z)): 0.2932 / 0.1904\n[0/1][505/938] Loss_D: 0.7948 Loss_G: 1.4066 D(x): 0.6596 D(G(z)): 0.2582 / 0.2744\n[0/1][506/938] Loss_D: 0.7771 Loss_G: 2.8630 D(x): 0.8301 D(G(z)): 0.4114 / 0.0700\n[0/1][507/938] Loss_D: 0.9722 Loss_G: 0.7308 D(x): 0.4991 D(G(z)): 0.1520 / 0.5145\n[0/1][508/938] Loss_D: 0.9707 Loss_G: 3.4862 D(x): 0.8805 D(G(z)): 0.5320 / 0.0388\n[0/1][509/938] Loss_D: 1.0714 Loss_G: 0.7709 D(x): 0.4125 D(G(z)): 0.0765 / 0.5104\n[0/1][510/938] Loss_D: 1.2410 Loss_G: 2.9036 D(x): 0.8880 D(G(z)): 0.6220 / 0.0783\n[0/1][511/938] Loss_D: 1.0199 Loss_G: 1.0365 D(x): 0.4853 D(G(z)): 0.1334 / 0.4065\n[0/1][512/938] Loss_D: 0.9100 Loss_G: 2.6441 D(x): 0.8308 D(G(z)): 0.4660 / 0.0892\n[0/1][513/938] Loss_D: 0.8486 Loss_G: 1.3203 D(x): 0.5693 D(G(z)): 0.1644 / 0.3203\n[0/1][514/938] Loss_D: 0.8480 Loss_G: 2.9401 D(x): 0.8543 D(G(z)): 0.4465 / 0.0724\n[0/1][515/938] Loss_D: 1.0131 Loss_G: 0.7800 D(x): 0.4938 D(G(z)): 0.1416 / 0.5251\n[0/1][516/938] Loss_D: 1.2018 Loss_G: 3.5468 D(x): 0.9217 D(G(z)): 0.5767 / 0.0453\n[0/1][517/938] Loss_D: 1.2022 Loss_G: 0.9366 D(x): 0.3961 D(G(z)): 0.0816 / 0.4421\n[0/1][518/938] Loss_D: 0.9050 Loss_G: 2.9611 D(x): 0.8944 D(G(z)): 0.4819 / 0.0736\n[0/1][519/938] Loss_D: 1.1757 Loss_G: 0.8602 D(x): 0.4294 D(G(z)): 0.1757 / 0.4731\n[0/1][520/938] Loss_D: 1.0008 Loss_G: 4.4845 D(x): 0.8963 D(G(z)): 0.5057 / 0.0219\n[0/1][521/938] Loss_D: 1.8805 Loss_G: 0.2445 D(x): 0.2123 D(G(z)): 0.0493 / 0.8048\n[0/1][522/938] Loss_D: 1.8967 Loss_G: 3.5092 D(x): 0.9727 D(G(z)): 0.7837 / 0.0485\n[0/1][523/938] Loss_D: 1.3334 Loss_G: 1.4515 D(x): 0.3812 D(G(z)): 0.1034 / 0.2935\n[0/1][524/938] Loss_D: 0.9160 Loss_G: 1.1937 D(x): 0.7410 D(G(z)): 0.3991 / 0.3318\n[0/1][525/938] Loss_D: 0.9370 Loss_G: 1.6643 D(x): 0.7062 D(G(z)): 0.3854 / 0.2176\n[0/1][526/938] Loss_D: 0.8761 Loss_G: 1.4290 D(x): 0.6494 D(G(z)): 0.3149 / 0.2841\n[0/1][527/938] Loss_D: 0.9924 Loss_G: 1.4469 D(x): 0.6634 D(G(z)): 0.3750 / 0.2724\n[0/1][528/938] Loss_D: 0.8517 Loss_G: 1.6338 D(x): 0.6804 D(G(z)): 0.3233 / 0.2224\n[0/1][529/938] Loss_D: 0.8966 Loss_G: 1.9330 D(x): 0.7065 D(G(z)): 0.3636 / 0.1770\n[0/1][530/938] Loss_D: 0.9427 Loss_G: 1.5580 D(x): 0.6358 D(G(z)): 0.3273 / 0.2420\n[0/1][531/938] Loss_D: 0.9468 Loss_G: 1.3532 D(x): 0.6296 D(G(z)): 0.3240 / 0.2999\n[0/1][532/938] Loss_D: 0.9321 Loss_G: 2.1080 D(x): 0.7219 D(G(z)): 0.3957 / 0.1461\n[0/1][533/938] Loss_D: 0.9767 Loss_G: 1.0369 D(x): 0.5656 D(G(z)): 0.2621 / 0.3861\n[0/1][534/938] Loss_D: 0.9733 Loss_G: 2.8082 D(x): 0.7845 D(G(z)): 0.4745 / 0.0725\n[0/1][535/938] Loss_D: 1.2932 Loss_G: 0.5851 D(x): 0.3519 D(G(z)): 0.1087 / 0.5990\n[0/1][536/938] Loss_D: 1.5211 Loss_G: 3.1221 D(x): 0.9156 D(G(z)): 0.7003 / 0.0551\n[0/1][537/938] Loss_D: 1.1089 Loss_G: 1.0857 D(x): 0.4095 D(G(z)): 0.1071 / 0.3876\n[0/1][538/938] Loss_D: 0.7601 Loss_G: 2.0169 D(x): 0.8397 D(G(z)): 0.4109 / 0.1585\n[0/1][539/938] Loss_D: 0.7133 Loss_G: 2.1043 D(x): 0.7347 D(G(z)): 0.2911 / 0.1466\n[0/1][540/938] Loss_D: 0.7877 Loss_G: 0.9653 D(x): 0.5857 D(G(z)): 0.1758 / 0.4157\n[0/1][541/938] Loss_D: 0.9463 Loss_G: 2.9595 D(x): 0.8856 D(G(z)): 0.5210 / 0.0710\n[0/1][542/938] Loss_D: 1.1217 Loss_G: 1.1044 D(x): 0.4548 D(G(z)): 0.1685 / 0.3815\n[0/1][543/938] Loss_D: 0.9212 Loss_G: 2.9512 D(x): 0.8792 D(G(z)): 0.4972 / 0.0701\n[0/1][544/938] Loss_D: 0.8771 Loss_G: 1.0485 D(x): 0.5149 D(G(z)): 0.1135 / 0.4021\n[0/1][545/938] Loss_D: 0.7968 Loss_G: 2.7151 D(x): 0.8600 D(G(z)): 0.4247 / 0.0924\n[0/1][546/938] Loss_D: 0.8324 Loss_G: 1.7038 D(x): 0.6433 D(G(z)): 0.2302 / 0.2213\n[0/1][547/938] Loss_D: 0.7662 Loss_G: 2.0108 D(x): 0.7410 D(G(z)): 0.3166 / 0.1635\n[0/1][548/938] Loss_D: 0.6974 Loss_G: 1.4385 D(x): 0.6680 D(G(z)): 0.2099 / 0.2779\n[0/1][549/938] Loss_D: 0.6074 Loss_G: 3.0383 D(x): 0.8500 D(G(z)): 0.3303 / 0.0645\n[0/1][550/938] Loss_D: 0.8243 Loss_G: 0.8731 D(x): 0.5657 D(G(z)): 0.1489 / 0.4641\n[0/1][551/938] Loss_D: 0.9830 Loss_G: 3.8274 D(x): 0.9068 D(G(z)): 0.5402 / 0.0358\n[0/1][552/938] Loss_D: 1.4050 Loss_G: 0.6106 D(x): 0.3552 D(G(z)): 0.1028 / 0.5998\n[0/1][553/938] Loss_D: 1.3499 Loss_G: 3.0794 D(x): 0.9143 D(G(z)): 0.6161 / 0.0709\n[0/1][554/938] Loss_D: 1.0638 Loss_G: 0.9005 D(x): 0.4550 D(G(z)): 0.1261 / 0.4593\n[0/1][555/938] Loss_D: 1.0391 Loss_G: 3.3419 D(x): 0.9012 D(G(z)): 0.5632 / 0.0504\n[0/1][556/938] Loss_D: 1.2848 Loss_G: 0.7233 D(x): 0.3861 D(G(z)): 0.1149 / 0.5260\n[0/1][557/938] Loss_D: 0.9524 Loss_G: 3.3987 D(x): 0.9497 D(G(z)): 0.5518 / 0.0444\n[0/1][558/938] Loss_D: 0.9614 Loss_G: 1.3407 D(x): 0.5009 D(G(z)): 0.1083 / 0.3055\n[0/1][559/938] Loss_D: 0.6213 Loss_G: 2.4538 D(x): 0.8789 D(G(z)): 0.3464 / 0.1130\n[0/1][560/938] Loss_D: 0.6071 Loss_G: 2.2978 D(x): 0.7454 D(G(z)): 0.2180 / 0.1361\n[0/1][561/938] Loss_D: 0.6972 Loss_G: 1.5298 D(x): 0.6938 D(G(z)): 0.2187 / 0.2623\n[0/1][562/938] Loss_D: 0.6061 Loss_G: 2.7905 D(x): 0.8478 D(G(z)): 0.3226 / 0.0720\n[0/1][563/938] Loss_D: 0.5957 Loss_G: 1.2978 D(x): 0.6491 D(G(z)): 0.1143 / 0.3149\n[0/1][564/938] Loss_D: 0.6778 Loss_G: 3.0252 D(x): 0.8880 D(G(z)): 0.3913 / 0.0624\n[0/1][565/938] Loss_D: 0.8035 Loss_G: 1.1263 D(x): 0.5733 D(G(z)): 0.1373 / 0.3680\n[0/1][566/938] Loss_D: 0.7178 Loss_G: 3.5757 D(x): 0.9043 D(G(z)): 0.4164 / 0.0348\n[0/1][567/938] Loss_D: 0.8540 Loss_G: 1.2779 D(x): 0.5106 D(G(z)): 0.0568 / 0.3769\n[0/1][568/938] Loss_D: 0.7691 Loss_G: 3.5662 D(x): 0.8908 D(G(z)): 0.4100 / 0.0425\n[0/1][569/938] Loss_D: 1.5671 Loss_G: 0.3919 D(x): 0.3061 D(G(z)): 0.1000 / 0.7219\n[0/1][570/938] Loss_D: 1.7286 Loss_G: 4.4110 D(x): 0.8892 D(G(z)): 0.7172 / 0.0180\n[0/1][571/938] Loss_D: 2.6556 Loss_G: 0.1989 D(x): 0.0911 D(G(z)): 0.0332 / 0.8370\n[0/1][572/938] Loss_D: 2.6931 Loss_G: 2.4268 D(x): 0.9565 D(G(z)): 0.8804 / 0.1323\n[0/1][573/938] Loss_D: 1.6320 Loss_G: 1.3583 D(x): 0.3728 D(G(z)): 0.2553 / 0.3180\n[0/1][574/938] Loss_D: 1.3208 Loss_G: 0.6707 D(x): 0.5149 D(G(z)): 0.3771 / 0.5422\n[0/1][575/938] Loss_D: 1.3740 Loss_G: 2.7599 D(x): 0.8082 D(G(z)): 0.6311 / 0.0921\n[0/1][576/938] Loss_D: 1.7505 Loss_G: 0.5105 D(x): 0.2730 D(G(z)): 0.1835 / 0.6337\n[0/1][577/938] Loss_D: 1.7082 Loss_G: 2.6990 D(x): 0.8572 D(G(z)): 0.7272 / 0.0959\n[0/1][578/938] Loss_D: 1.4734 Loss_G: 0.8704 D(x): 0.3384 D(G(z)): 0.1936 / 0.4677\n[0/1][579/938] Loss_D: 1.2800 Loss_G: 1.4340 D(x): 0.6996 D(G(z)): 0.5225 / 0.2848\n[0/1][580/938] Loss_D: 1.0876 Loss_G: 1.5084 D(x): 0.6027 D(G(z)): 0.3444 / 0.2777\n[0/1][581/938] Loss_D: 1.1520 Loss_G: 1.5599 D(x): 0.6145 D(G(z)): 0.4068 / 0.2707\n[0/1][582/938] Loss_D: 1.0739 Loss_G: 3.0999 D(x): 0.6981 D(G(z)): 0.4343 / 0.0727\n[0/1][583/938] Loss_D: 1.0797 Loss_G: 0.8788 D(x): 0.5204 D(G(z)): 0.1772 / 0.4518\n[0/1][584/938] Loss_D: 0.9442 Loss_G: 3.9855 D(x): 0.9134 D(G(z)): 0.5230 / 0.0274\n[0/1][585/938] Loss_D: 1.2397 Loss_G: 0.6237 D(x): 0.3801 D(G(z)): 0.0883 / 0.5780\n[0/1][586/938] Loss_D: 1.5993 Loss_G: 5.2766 D(x): 0.9542 D(G(z)): 0.7346 / 0.0069\n[0/1][587/938] Loss_D: 2.9179 Loss_G: 0.5462 D(x): 0.0747 D(G(z)): 0.0152 / 0.6147\n[0/1][588/938] Loss_D: 1.4007 Loss_G: 2.1674 D(x): 0.9163 D(G(z)): 0.6798 / 0.1506\n[0/1][589/938] Loss_D: 1.0024 Loss_G: 1.8189 D(x): 0.5654 D(G(z)): 0.2757 / 0.2083\n[0/1][590/938] Loss_D: 1.0104 Loss_G: 1.2258 D(x): 0.6070 D(G(z)): 0.3352 / 0.3408\n[0/1][591/938] Loss_D: 0.9883 Loss_G: 2.1534 D(x): 0.7447 D(G(z)): 0.4452 / 0.1474\n[0/1][592/938] Loss_D: 0.6750 Loss_G: 1.7767 D(x): 0.6726 D(G(z)): 0.1985 / 0.2053\n[0/1][593/938] Loss_D: 0.8090 Loss_G: 2.0297 D(x): 0.7584 D(G(z)): 0.3661 / 0.1525\n[0/1][594/938] Loss_D: 0.8116 Loss_G: 1.1336 D(x): 0.6187 D(G(z)): 0.2293 / 0.3730\n[0/1][595/938] Loss_D: 0.8761 Loss_G: 3.9201 D(x): 0.8880 D(G(z)): 0.4909 / 0.0248\n[0/1][596/938] Loss_D: 1.4432 Loss_G: 0.7241 D(x): 0.3016 D(G(z)): 0.0479 / 0.5499\n[0/1][597/938] Loss_D: 1.4543 Loss_G: 3.1005 D(x): 0.9190 D(G(z)): 0.6557 / 0.0649\n[0/1][598/938] Loss_D: 0.7952 Loss_G: 1.7069 D(x): 0.5652 D(G(z)): 0.1134 / 0.2271\n[0/1][599/938] Loss_D: 0.7758 Loss_G: 1.6517 D(x): 0.7695 D(G(z)): 0.3535 / 0.2273\n[0/1][600/938] Loss_D: 0.7518 Loss_G: 2.6220 D(x): 0.8009 D(G(z)): 0.3717 / 0.0879\n[0/1][601/938] Loss_D: 0.7006 Loss_G: 1.8615 D(x): 0.6492 D(G(z)): 0.1913 / 0.1845\n[0/1][602/938] Loss_D: 0.4968 Loss_G: 2.0463 D(x): 0.8168 D(G(z)): 0.2350 / 0.1513\n[0/1][603/938] Loss_D: 0.6030 Loss_G: 2.5160 D(x): 0.8002 D(G(z)): 0.2734 / 0.0993\n[0/1][604/938] Loss_D: 0.6691 Loss_G: 1.4061 D(x): 0.6713 D(G(z)): 0.1828 / 0.2873\n[0/1][605/938] Loss_D: 0.6579 Loss_G: 3.3668 D(x): 0.8986 D(G(z)): 0.3852 / 0.0459\n[0/1][606/938] Loss_D: 0.7890 Loss_G: 1.1050 D(x): 0.5381 D(G(z)): 0.0768 / 0.3826\n[0/1][607/938] Loss_D: 0.7842 Loss_G: 3.0463 D(x): 0.9018 D(G(z)): 0.4487 / 0.0607\n[0/1][608/938] Loss_D: 0.7217 Loss_G: 1.4612 D(x): 0.5930 D(G(z)): 0.1106 / 0.2783\n[0/1][609/938] Loss_D: 0.7068 Loss_G: 3.6898 D(x): 0.8778 D(G(z)): 0.3998 / 0.0362\n[0/1][610/938] Loss_D: 1.0768 Loss_G: 0.5075 D(x): 0.4445 D(G(z)): 0.0890 / 0.6534\n[0/1][611/938] Loss_D: 1.6960 Loss_G: 4.5343 D(x): 0.9642 D(G(z)): 0.7368 / 0.0271\n[0/1][612/938] Loss_D: 1.4200 Loss_G: 1.1454 D(x): 0.3522 D(G(z)): 0.0509 / 0.4110\n[0/1][613/938] Loss_D: 0.8790 Loss_G: 3.7649 D(x): 0.9274 D(G(z)): 0.5011 / 0.0391\n[0/1][614/938] Loss_D: 1.4700 Loss_G: 0.5645 D(x): 0.3472 D(G(z)): 0.0850 / 0.6153\n[0/1][615/938] Loss_D: 1.5114 Loss_G: 5.0243 D(x): 0.9767 D(G(z)): 0.7182 / 0.0093\n[0/1][616/938] Loss_D: 2.5175 Loss_G: 0.9368 D(x): 0.1321 D(G(z)): 0.0259 / 0.4594\n[0/1][617/938] Loss_D: 1.3871 Loss_G: 1.7571 D(x): 0.8535 D(G(z)): 0.6197 / 0.2220\n[0/1][618/938] Loss_D: 1.0992 Loss_G: 2.0289 D(x): 0.6288 D(G(z)): 0.3256 / 0.1737\n[0/1][619/938] Loss_D: 1.1357 Loss_G: 0.8021 D(x): 0.4993 D(G(z)): 0.2409 / 0.4919\n[0/1][620/938] Loss_D: 1.3074 Loss_G: 2.6727 D(x): 0.8148 D(G(z)): 0.6028 / 0.0964\n[0/1][621/938] Loss_D: 1.0052 Loss_G: 1.5762 D(x): 0.5188 D(G(z)): 0.1655 / 0.2722\n[0/1][622/938] Loss_D: 0.8814 Loss_G: 1.7947 D(x): 0.7468 D(G(z)): 0.3952 / 0.1966\n[0/1][623/938] Loss_D: 0.7560 Loss_G: 1.9644 D(x): 0.7188 D(G(z)): 0.3054 / 0.1714\n[0/1][624/938] Loss_D: 0.6665 Loss_G: 1.7208 D(x): 0.7270 D(G(z)): 0.2499 / 0.2234\n[0/1][625/938] Loss_D: 0.6914 Loss_G: 2.0590 D(x): 0.7725 D(G(z)): 0.3007 / 0.1559\n[0/1][626/938] Loss_D: 0.6639 Loss_G: 2.1565 D(x): 0.7246 D(G(z)): 0.2425 / 0.1433\n[0/1][627/938] Loss_D: 0.6197 Loss_G: 1.8527 D(x): 0.7321 D(G(z)): 0.2185 / 0.1779\n[0/1][628/938] Loss_D: 0.6865 Loss_G: 2.3200 D(x): 0.7763 D(G(z)): 0.3103 / 0.1209\n[0/1][629/938] Loss_D: 0.6049 Loss_G: 1.5894 D(x): 0.6946 D(G(z)): 0.1781 / 0.2262\n[0/1][630/938] Loss_D: 0.6387 Loss_G: 3.0675 D(x): 0.8495 D(G(z)): 0.3497 / 0.0702\n[0/1][631/938] Loss_D: 0.8322 Loss_G: 0.9700 D(x): 0.5426 D(G(z)): 0.1134 / 0.4164\n[0/1][632/938] Loss_D: 0.8847 Loss_G: 3.5553 D(x): 0.9205 D(G(z)): 0.5190 / 0.0361\n[0/1][633/938] Loss_D: 0.7971 Loss_G: 1.5205 D(x): 0.5367 D(G(z)): 0.0710 / 0.2655\n[0/1][634/938] Loss_D: 0.6070 Loss_G: 2.5250 D(x): 0.8861 D(G(z)): 0.3564 / 0.1022\n[0/1][635/938] Loss_D: 0.6801 Loss_G: 1.7459 D(x): 0.6923 D(G(z)): 0.2067 / 0.2112\n[0/1][636/938] Loss_D: 0.5284 Loss_G: 2.7040 D(x): 0.8422 D(G(z)): 0.2725 / 0.0857\n[0/1][637/938] Loss_D: 0.6340 Loss_G: 1.0775 D(x): 0.6521 D(G(z)): 0.1373 / 0.3972\n[0/1][638/938] Loss_D: 1.0654 Loss_G: 5.0381 D(x): 0.9489 D(G(z)): 0.5685 / 0.0084\n[0/1][639/938] Loss_D: 2.2413 Loss_G: 1.3319 D(x): 0.1424 D(G(z)): 0.0201 / 0.3407\n[0/1][640/938] Loss_D: 0.7285 Loss_G: 2.6143 D(x): 0.8514 D(G(z)): 0.3739 / 0.0930\n[0/1][641/938] Loss_D: 1.0777 Loss_G: 0.4853 D(x): 0.4761 D(G(z)): 0.1813 / 0.6387\n[0/1][642/938] Loss_D: 1.5087 Loss_G: 3.5646 D(x): 0.9000 D(G(z)): 0.7136 / 0.0433\n[0/1][643/938] Loss_D: 2.1062 Loss_G: 0.4331 D(x): 0.1822 D(G(z)): 0.0736 / 0.6782\n[0/1][644/938] Loss_D: 1.7373 Loss_G: 2.3942 D(x): 0.9143 D(G(z)): 0.7428 / 0.1257\n[0/1][645/938] Loss_D: 1.1514 Loss_G: 1.4684 D(x): 0.4690 D(G(z)): 0.2111 / 0.2752\n[0/1][646/938] Loss_D: 0.9653 Loss_G: 1.1244 D(x): 0.6340 D(G(z)): 0.3303 / 0.3643\n[0/1][647/938] Loss_D: 1.0741 Loss_G: 2.6684 D(x): 0.7738 D(G(z)): 0.4912 / 0.0989\n[0/1][648/938] Loss_D: 1.1672 Loss_G: 0.8161 D(x): 0.4460 D(G(z)): 0.1841 / 0.5079\n[0/1][649/938] Loss_D: 1.4718 Loss_G: 3.3864 D(x): 0.8481 D(G(z)): 0.6274 / 0.0618\n[0/1][650/938] Loss_D: 1.2980 Loss_G: 0.8763 D(x): 0.3804 D(G(z)): 0.1109 / 0.4727\n[0/1][651/938] Loss_D: 1.1154 Loss_G: 1.8002 D(x): 0.8124 D(G(z)): 0.5486 / 0.1924\n[0/1][652/938] Loss_D: 1.1498 Loss_G: 1.6264 D(x): 0.5848 D(G(z)): 0.3798 / 0.2306\n[0/1][653/938] Loss_D: 1.0653 Loss_G: 1.0110 D(x): 0.5480 D(G(z)): 0.3124 / 0.3914\n[0/1][654/938] Loss_D: 1.0105 Loss_G: 2.0509 D(x): 0.7283 D(G(z)): 0.4491 / 0.1536\n[0/1][655/938] Loss_D: 0.9564 Loss_G: 1.0426 D(x): 0.5257 D(G(z)): 0.2106 / 0.3845\n[0/1][656/938] Loss_D: 1.0913 Loss_G: 2.3403 D(x): 0.8060 D(G(z)): 0.5239 / 0.1242\n[0/1][657/938] Loss_D: 0.8824 Loss_G: 1.2973 D(x): 0.5735 D(G(z)): 0.1893 / 0.3163\n[0/1][658/938] Loss_D: 0.9975 Loss_G: 2.3856 D(x): 0.8118 D(G(z)): 0.4779 / 0.1183\n[0/1][659/938] Loss_D: 0.9027 Loss_G: 1.3173 D(x): 0.5754 D(G(z)): 0.2179 / 0.3042\n[0/1][660/938] Loss_D: 0.7382 Loss_G: 2.1502 D(x): 0.7889 D(G(z)): 0.3550 / 0.1485\n[0/1][661/938] Loss_D: 0.7897 Loss_G: 1.5844 D(x): 0.6674 D(G(z)): 0.2508 / 0.2603\n[0/1][662/938] Loss_D: 0.7732 Loss_G: 2.6773 D(x): 0.7930 D(G(z)): 0.3713 / 0.0916\n[0/1][663/938] Loss_D: 0.6896 Loss_G: 1.6078 D(x): 0.6559 D(G(z)): 0.1706 / 0.2286\n[0/1][664/938] Loss_D: 0.6356 Loss_G: 2.2342 D(x): 0.7954 D(G(z)): 0.2985 / 0.1309\n[0/1][665/938] Loss_D: 0.6320 Loss_G: 1.8983 D(x): 0.7263 D(G(z)): 0.2332 / 0.1802\n[0/1][666/938] Loss_D: 0.7539 Loss_G: 1.9401 D(x): 0.7196 D(G(z)): 0.3014 / 0.1709\n[0/1][667/938] Loss_D: 0.7780 Loss_G: 2.3630 D(x): 0.7268 D(G(z)): 0.3076 / 0.1270\n[0/1][668/938] Loss_D: 0.6977 Loss_G: 0.8722 D(x): 0.6361 D(G(z)): 0.1546 / 0.4522\n[0/1][669/938] Loss_D: 1.2054 Loss_G: 5.0875 D(x): 0.9637 D(G(z)): 0.6359 / 0.0105\n[0/1][670/938] Loss_D: 2.3474 Loss_G: 0.5991 D(x): 0.1566 D(G(z)): 0.0224 / 0.6012\n[0/1][671/938] Loss_D: 1.3301 Loss_G: 4.7027 D(x): 0.9395 D(G(z)): 0.6222 / 0.0165\n[0/1][672/938] Loss_D: 2.1488 Loss_G: 0.2137 D(x): 0.1899 D(G(z)): 0.0735 / 0.8322\n[0/1][673/938] Loss_D: 2.4126 Loss_G: 3.4076 D(x): 0.9755 D(G(z)): 0.8527 / 0.0758\n[0/1][674/938] Loss_D: 1.3107 Loss_G: 0.8616 D(x): 0.4463 D(G(z)): 0.2008 / 0.4733\n[0/1][675/938] Loss_D: 0.9111 Loss_G: 2.8318 D(x): 0.8213 D(G(z)): 0.4624 / 0.0794\n[0/1][676/938] Loss_D: 1.1759 Loss_G: 0.8593 D(x): 0.4435 D(G(z)): 0.2006 / 0.4593\n[0/1][677/938] Loss_D: 1.0202 Loss_G: 2.4197 D(x): 0.8269 D(G(z)): 0.5180 / 0.1127\n[0/1][678/938] Loss_D: 0.9434 Loss_G: 1.2953 D(x): 0.5507 D(G(z)): 0.2246 / 0.3140\n[0/1][679/938] Loss_D: 0.8385 Loss_G: 1.3360 D(x): 0.6949 D(G(z)): 0.3240 / 0.3031\n[0/1][680/938] Loss_D: 0.8830 Loss_G: 2.5171 D(x): 0.8086 D(G(z)): 0.4358 / 0.0992\n[0/1][681/938] Loss_D: 0.9943 Loss_G: 0.7937 D(x): 0.4645 D(G(z)): 0.1170 / 0.4993\n[0/1][682/938] Loss_D: 1.4250 Loss_G: 2.8095 D(x): 0.8688 D(G(z)): 0.6429 / 0.0730\n[0/1][683/938] Loss_D: 0.8418 Loss_G: 1.5565 D(x): 0.5469 D(G(z)): 0.1537 / 0.2650\n[0/1][684/938] Loss_D: 0.8985 Loss_G: 1.5598 D(x): 0.7152 D(G(z)): 0.3675 / 0.2444\n[0/1][685/938] Loss_D: 0.7536 Loss_G: 2.1401 D(x): 0.7542 D(G(z)): 0.3312 / 0.1431\n[0/1][686/938] Loss_D: 0.8616 Loss_G: 0.9177 D(x): 0.5686 D(G(z)): 0.1804 / 0.4543\n[0/1][687/938] Loss_D: 0.8704 Loss_G: 4.3736 D(x): 0.9026 D(G(z)): 0.4833 / 0.0164\n[0/1][688/938] Loss_D: 1.4828 Loss_G: 0.8886 D(x): 0.3267 D(G(z)): 0.0884 / 0.4638\n[0/1][689/938] Loss_D: 1.1020 Loss_G: 4.0189 D(x): 0.8977 D(G(z)): 0.5673 / 0.0313\n[0/1][690/938] Loss_D: 1.8124 Loss_G: 0.3603 D(x): 0.2585 D(G(z)): 0.0784 / 0.7305\n[0/1][691/938] Loss_D: 1.7254 Loss_G: 2.9986 D(x): 0.9495 D(G(z)): 0.7704 / 0.0725\n[0/1][692/938] Loss_D: 1.0955 Loss_G: 1.6616 D(x): 0.5171 D(G(z)): 0.2263 / 0.2514\n[0/1][693/938] Loss_D: 1.0226 Loss_G: 1.2726 D(x): 0.6237 D(G(z)): 0.3367 / 0.3239\n[0/1][694/938] Loss_D: 1.0311 Loss_G: 3.0570 D(x): 0.7701 D(G(z)): 0.4810 / 0.0675\n[0/1][695/938] Loss_D: 1.0542 Loss_G: 1.0633 D(x): 0.4531 D(G(z)): 0.1207 / 0.4031\n[0/1][696/938] Loss_D: 1.0164 Loss_G: 2.1640 D(x): 0.8208 D(G(z)): 0.4939 / 0.1499\n[0/1][697/938] Loss_D: 0.8445 Loss_G: 1.6774 D(x): 0.6268 D(G(z)): 0.2553 / 0.2183\n[0/1][698/938] Loss_D: 0.7992 Loss_G: 1.7175 D(x): 0.7144 D(G(z)): 0.3360 / 0.2107\n[0/1][699/938] Loss_D: 0.7755 Loss_G: 2.2184 D(x): 0.7176 D(G(z)): 0.3084 / 0.1388\n[0/1][700/938] Loss_D: 0.6060 Loss_G: 2.0506 D(x): 0.7483 D(G(z)): 0.2289 / 0.1609\n[0/1][701/938] Loss_D: 0.7048 Loss_G: 1.9779 D(x): 0.7314 D(G(z)): 0.2690 / 0.1640\n[0/1][702/938] Loss_D: 0.6932 Loss_G: 2.1132 D(x): 0.7387 D(G(z)): 0.2794 / 0.1442\n[0/1][703/938] Loss_D: 0.6046 Loss_G: 2.4676 D(x): 0.7935 D(G(z)): 0.2648 / 0.1117\n[0/1][704/938] Loss_D: 0.7895 Loss_G: 1.4887 D(x): 0.6200 D(G(z)): 0.1976 / 0.2759\n[0/1][705/938] Loss_D: 0.7894 Loss_G: 2.9013 D(x): 0.8369 D(G(z)): 0.4003 / 0.0673\n[0/1][706/938] Loss_D: 0.7765 Loss_G: 1.1281 D(x): 0.5597 D(G(z)): 0.1181 / 0.3821\n[0/1][707/938] Loss_D: 0.8050 Loss_G: 3.8213 D(x): 0.8986 D(G(z)): 0.4533 / 0.0354\n[0/1][708/938] Loss_D: 0.8892 Loss_G: 1.0685 D(x): 0.5383 D(G(z)): 0.1133 / 0.3966\n[0/1][709/938] Loss_D: 0.8880 Loss_G: 3.7992 D(x): 0.9306 D(G(z)): 0.5125 / 0.0296\n[0/1][710/938] Loss_D: 1.0822 Loss_G: 1.0609 D(x): 0.4281 D(G(z)): 0.0652 / 0.4194\n[0/1][711/938] Loss_D: 1.2017 Loss_G: 2.3775 D(x): 0.8427 D(G(z)): 0.5432 / 0.1199\n[0/1][712/938] Loss_D: 0.6188 Loss_G: 2.2622 D(x): 0.7109 D(G(z)): 0.1921 / 0.1448\n[0/1][713/938] Loss_D: 0.6683 Loss_G: 1.4729 D(x): 0.6913 D(G(z)): 0.2007 / 0.2779\n[0/1][714/938] Loss_D: 0.7677 Loss_G: 3.4092 D(x): 0.8453 D(G(z)): 0.3881 / 0.0472\n[0/1][715/938] Loss_D: 0.9120 Loss_G: 1.0257 D(x): 0.5263 D(G(z)): 0.1416 / 0.4067\n[0/1][716/938] Loss_D: 0.8895 Loss_G: 3.2236 D(x): 0.8881 D(G(z)): 0.4845 / 0.0523\n[0/1][717/938] Loss_D: 0.9958 Loss_G: 1.1861 D(x): 0.4974 D(G(z)): 0.1182 / 0.3521\n[0/1][718/938] Loss_D: 0.8443 Loss_G: 2.5773 D(x): 0.8505 D(G(z)): 0.4216 / 0.1154\n[0/1][719/938] Loss_D: 0.7594 Loss_G: 1.5488 D(x): 0.6484 D(G(z)): 0.2136 / 0.2429\n[0/1][720/938] Loss_D: 0.8122 Loss_G: 2.3666 D(x): 0.7727 D(G(z)): 0.3512 / 0.1177\n[0/1][721/938] Loss_D: 0.5722 Loss_G: 1.7949 D(x): 0.7286 D(G(z)): 0.1636 / 0.2102\n[0/1][722/938] Loss_D: 0.6743 Loss_G: 3.7839 D(x): 0.8591 D(G(z)): 0.3534 / 0.0311\n[0/1][723/938] Loss_D: 1.0041 Loss_G: 0.5738 D(x): 0.4468 D(G(z)): 0.0620 / 0.6070\n[0/1][724/938] Loss_D: 1.3857 Loss_G: 4.6175 D(x): 0.9751 D(G(z)): 0.6816 / 0.0159\n[0/1][725/938] Loss_D: 1.4624 Loss_G: 0.5066 D(x): 0.3003 D(G(z)): 0.0551 / 0.6415\n[0/1][726/938] Loss_D: 1.7280 Loss_G: 3.9544 D(x): 0.9337 D(G(z)): 0.7225 / 0.0411\n[0/1][727/938] Loss_D: 1.4121 Loss_G: 1.1548 D(x): 0.3339 D(G(z)): 0.0753 / 0.3723\n[0/1][728/938] Loss_D: 0.8191 Loss_G: 2.6278 D(x): 0.8670 D(G(z)): 0.4281 / 0.1038\n[0/1][729/938] Loss_D: 0.8223 Loss_G: 1.4797 D(x): 0.6389 D(G(z)): 0.2135 / 0.2616\n[0/1][730/938] Loss_D: 0.8749 Loss_G: 2.0975 D(x): 0.7537 D(G(z)): 0.3790 / 0.1601\n[0/1][731/938] Loss_D: 0.6314 Loss_G: 2.4086 D(x): 0.7694 D(G(z)): 0.2631 / 0.1110\n[0/1][732/938] Loss_D: 0.7979 Loss_G: 1.1141 D(x): 0.5947 D(G(z)): 0.1799 / 0.3807\n[0/1][733/938] Loss_D: 1.0465 Loss_G: 4.1084 D(x): 0.9016 D(G(z)): 0.5508 / 0.0212\n[0/1][734/938] Loss_D: 1.4809 Loss_G: 0.8993 D(x): 0.2975 D(G(z)): 0.0468 / 0.4631\n[0/1][735/938] Loss_D: 1.0937 Loss_G: 3.8785 D(x): 0.8692 D(G(z)): 0.5452 / 0.0284\n[0/1][736/938] Loss_D: 1.9454 Loss_G: 0.1605 D(x): 0.1941 D(G(z)): 0.0719 / 0.8595\n[0/1][737/938] Loss_D: 2.5410 Loss_G: 3.1183 D(x): 0.9710 D(G(z)): 0.8882 / 0.0989\n[0/1][738/938] Loss_D: 1.1500 Loss_G: 1.6797 D(x): 0.5180 D(G(z)): 0.1862 / 0.2357\n[0/1][739/938] Loss_D: 0.8476 Loss_G: 2.2702 D(x): 0.7740 D(G(z)): 0.3816 / 0.1391\n[0/1][740/938] Loss_D: 0.9581 Loss_G: 1.9494 D(x): 0.6322 D(G(z)): 0.2759 / 0.2049\n[0/1][741/938] Loss_D: 0.8748 Loss_G: 1.7921 D(x): 0.6793 D(G(z)): 0.3295 / 0.1938\n[0/1][742/938] Loss_D: 0.9056 Loss_G: 2.1972 D(x): 0.6881 D(G(z)): 0.3519 / 0.1317\n[0/1][743/938] Loss_D: 0.5600 Loss_G: 1.5664 D(x): 0.7048 D(G(z)): 0.1623 / 0.2427\n[0/1][744/938] Loss_D: 0.8097 Loss_G: 3.5840 D(x): 0.8566 D(G(z)): 0.4230 / 0.0384\n[0/1][745/938] Loss_D: 0.9872 Loss_G: 0.9475 D(x): 0.4433 D(G(z)): 0.0677 / 0.4407\n[0/1][746/938] Loss_D: 1.3386 Loss_G: 3.4848 D(x): 0.9463 D(G(z)): 0.6810 / 0.0402\n[0/1][747/938] Loss_D: 1.2801 Loss_G: 1.1151 D(x): 0.3841 D(G(z)): 0.1132 / 0.3867\n[0/1][748/938] Loss_D: 0.8878 Loss_G: 2.3448 D(x): 0.8278 D(G(z)): 0.4355 / 0.1252\n[0/1][749/938] Loss_D: 0.5241 Loss_G: 2.4204 D(x): 0.7607 D(G(z)): 0.1871 / 0.1143\n[0/1][750/938] Loss_D: 0.7655 Loss_G: 2.0880 D(x): 0.7297 D(G(z)): 0.3030 / 0.1470\n[0/1][751/938] Loss_D: 0.7176 Loss_G: 1.3262 D(x): 0.6371 D(G(z)): 0.1840 / 0.3106\n[0/1][752/938] Loss_D: 0.5713 Loss_G: 2.5374 D(x): 0.8720 D(G(z)): 0.3239 / 0.0979\n[0/1][753/938] Loss_D: 0.5661 Loss_G: 2.4079 D(x): 0.7580 D(G(z)): 0.2185 / 0.1084\n[0/1][754/938] Loss_D: 0.6915 Loss_G: 1.5310 D(x): 0.6677 D(G(z)): 0.1983 / 0.2402\n[0/1][755/938] Loss_D: 0.6785 Loss_G: 2.6575 D(x): 0.8206 D(G(z)): 0.3522 / 0.0851\n[0/1][756/938] Loss_D: 0.9664 Loss_G: 0.6865 D(x): 0.4864 D(G(z)): 0.1432 / 0.5528\n[0/1][757/938] Loss_D: 1.0097 Loss_G: 4.2444 D(x): 0.9475 D(G(z)): 0.5680 / 0.0280\n[0/1][758/938] Loss_D: 1.3660 Loss_G: 0.8324 D(x): 0.3671 D(G(z)): 0.0874 / 0.4989\n[0/1][759/938] Loss_D: 1.1035 Loss_G: 2.8091 D(x): 0.9269 D(G(z)): 0.5604 / 0.0900\n[0/1][760/938] Loss_D: 0.8160 Loss_G: 1.8846 D(x): 0.6433 D(G(z)): 0.2267 / 0.1892\n[0/1][761/938] Loss_D: 0.8857 Loss_G: 1.6631 D(x): 0.6839 D(G(z)): 0.3495 / 0.2332\n[0/1][762/938] Loss_D: 0.8963 Loss_G: 1.6798 D(x): 0.6645 D(G(z)): 0.3085 / 0.2193\n[0/1][763/938] Loss_D: 0.6793 Loss_G: 2.3179 D(x): 0.7615 D(G(z)): 0.3028 / 0.1241\n[0/1][764/938] Loss_D: 0.7011 Loss_G: 1.4686 D(x): 0.6765 D(G(z)): 0.2081 / 0.2846\n[0/1][765/938] Loss_D: 0.8194 Loss_G: 3.7500 D(x): 0.8350 D(G(z)): 0.4216 / 0.0343\n[0/1][766/938] Loss_D: 1.0152 Loss_G: 0.9425 D(x): 0.4548 D(G(z)): 0.0836 / 0.4957\n[0/1][767/938] Loss_D: 1.0166 Loss_G: 3.5305 D(x): 0.8951 D(G(z)): 0.5061 / 0.0381\n[0/1][768/938] Loss_D: 1.0211 Loss_G: 1.1700 D(x): 0.5222 D(G(z)): 0.1403 / 0.3679\n[0/1][769/938] Loss_D: 0.8774 Loss_G: 3.2276 D(x): 0.8790 D(G(z)): 0.4451 / 0.0595\n[0/1][770/938] Loss_D: 0.7303 Loss_G: 1.5229 D(x): 0.6123 D(G(z)): 0.1345 / 0.2749\n[0/1][771/938] Loss_D: 0.8580 Loss_G: 3.3780 D(x): 0.8689 D(G(z)): 0.4540 / 0.0437\n[0/1][772/938] Loss_D: 1.0583 Loss_G: 0.9279 D(x): 0.4793 D(G(z)): 0.1049 / 0.4423\n[0/1][773/938] Loss_D: 1.0812 Loss_G: 4.3194 D(x): 0.9204 D(G(z)): 0.5726 / 0.0185\n[0/1][774/938] Loss_D: 1.0524 Loss_G: 1.8563 D(x): 0.4280 D(G(z)): 0.0547 / 0.2160\n[0/1][775/938] Loss_D: 0.7994 Loss_G: 2.7389 D(x): 0.8242 D(G(z)): 0.3839 / 0.0891\n[0/1][776/938] Loss_D: 0.9142 Loss_G: 0.4569 D(x): 0.5372 D(G(z)): 0.1389 / 0.6517\n[0/1][777/938] Loss_D: 1.5201 Loss_G: 3.8175 D(x): 0.9412 D(G(z)): 0.7187 / 0.0369\n[0/1][778/938] Loss_D: 1.6534 Loss_G: 0.7562 D(x): 0.2817 D(G(z)): 0.0829 / 0.5180\n[0/1][779/938] Loss_D: 1.2777 Loss_G: 3.1006 D(x): 0.8833 D(G(z)): 0.6170 / 0.0661\n[0/1][780/938] Loss_D: 0.8390 Loss_G: 1.7809 D(x): 0.6039 D(G(z)): 0.1876 / 0.2072\n[0/1][781/938] Loss_D: 0.7942 Loss_G: 1.6114 D(x): 0.6717 D(G(z)): 0.2563 / 0.2255\n[0/1][782/938] Loss_D: 0.5626 Loss_G: 3.9217 D(x): 0.8905 D(G(z)): 0.3284 / 0.0274\n[0/1][783/938] Loss_D: 0.7187 Loss_G: 1.3691 D(x): 0.5898 D(G(z)): 0.0999 / 0.3143\n[0/1][784/938] Loss_D: 0.8939 Loss_G: 4.1411 D(x): 0.9137 D(G(z)): 0.5003 / 0.0231\n[0/1][785/938] Loss_D: 1.3073 Loss_G: 0.6527 D(x): 0.3718 D(G(z)): 0.0657 / 0.5528\n[0/1][786/938] Loss_D: 1.0538 Loss_G: 3.2602 D(x): 0.8975 D(G(z)): 0.5678 / 0.0490\n[0/1][787/938] Loss_D: 1.1077 Loss_G: 1.2317 D(x): 0.4630 D(G(z)): 0.1392 / 0.3374\n[0/1][788/938] Loss_D: 0.8371 Loss_G: 2.8802 D(x): 0.8838 D(G(z)): 0.4466 / 0.0858\n[0/1][789/938] Loss_D: 0.8182 Loss_G: 1.8806 D(x): 0.6231 D(G(z)): 0.2172 / 0.1971\n[0/1][790/938] Loss_D: 0.5356 Loss_G: 1.9786 D(x): 0.7806 D(G(z)): 0.2207 / 0.1659\n[0/1][791/938] Loss_D: 0.6537 Loss_G: 3.5296 D(x): 0.8628 D(G(z)): 0.3502 / 0.0458\n[0/1][792/938] Loss_D: 1.1096 Loss_G: 1.1898 D(x): 0.4307 D(G(z)): 0.0799 / 0.3807\n[0/1][793/938] Loss_D: 1.1728 Loss_G: 4.7372 D(x): 0.9235 D(G(z)): 0.5892 / 0.0182\n[0/1][794/938] Loss_D: 2.1836 Loss_G: 0.9018 D(x): 0.1601 D(G(z)): 0.0293 / 0.4825\n[0/1][795/938] Loss_D: 1.2004 Loss_G: 4.7390 D(x): 0.9626 D(G(z)): 0.5606 / 0.0179\n[0/1][796/938] Loss_D: 2.2657 Loss_G: 0.0591 D(x): 0.1552 D(G(z)): 0.0786 / 0.9447\n[0/1][797/938] Loss_D: 3.2834 Loss_G: 4.0149 D(x): 0.9959 D(G(z)): 0.9349 / 0.0516\n[0/1][798/938] Loss_D: 0.9169 Loss_G: 2.9335 D(x): 0.6073 D(G(z)): 0.2314 / 0.0859\n[0/1][799/938] Loss_D: 1.4496 Loss_G: 0.4314 D(x): 0.3813 D(G(z)): 0.1502 / 0.6853\n[0/1][800/938] Loss_D: 2.0538 Loss_G: 3.6122 D(x): 0.9459 D(G(z)): 0.7887 / 0.0458\n[0/1][801/938] Loss_D: 1.3818 Loss_G: 1.1808 D(x): 0.3548 D(G(z)): 0.1449 / 0.3740\n[0/1][802/938] Loss_D: 0.9089 Loss_G: 1.9217 D(x): 0.7634 D(G(z)): 0.4013 / 0.1854\n[0/1][803/938] Loss_D: 1.0850 Loss_G: 1.9033 D(x): 0.6529 D(G(z)): 0.3980 / 0.1777\n[0/1][804/938] Loss_D: 0.9300 Loss_G: 1.8754 D(x): 0.6337 D(G(z)): 0.2964 / 0.2005\n[0/1][805/938] Loss_D: 0.8563 Loss_G: 2.0578 D(x): 0.7025 D(G(z)): 0.3470 / 0.1544\n[0/1][806/938] Loss_D: 0.7781 Loss_G: 2.1144 D(x): 0.6903 D(G(z)): 0.2722 / 0.1582\n[0/1][807/938] Loss_D: 0.7832 Loss_G: 2.1679 D(x): 0.7252 D(G(z)): 0.3247 / 0.1451\n[0/1][808/938] Loss_D: 0.8888 Loss_G: 2.0736 D(x): 0.6816 D(G(z)): 0.3307 / 0.1537\n[0/1][809/938] Loss_D: 0.8890 Loss_G: 1.3826 D(x): 0.5926 D(G(z)): 0.2425 / 0.2829\n[0/1][810/938] Loss_D: 0.9225 Loss_G: 2.7554 D(x): 0.8348 D(G(z)): 0.4759 / 0.0794\n[0/1][811/938] Loss_D: 0.6781 Loss_G: 1.8088 D(x): 0.6161 D(G(z)): 0.1338 / 0.2255\n[0/1][812/938] Loss_D: 0.6549 Loss_G: 2.3599 D(x): 0.8369 D(G(z)): 0.3389 / 0.1180\n[0/1][813/938] Loss_D: 0.6749 Loss_G: 1.7257 D(x): 0.6785 D(G(z)): 0.2029 / 0.2226\n[0/1][814/938] Loss_D: 0.7495 Loss_G: 2.1347 D(x): 0.7677 D(G(z)): 0.3410 / 0.1493\n[0/1][815/938] Loss_D: 0.7017 Loss_G: 1.6334 D(x): 0.6869 D(G(z)): 0.2207 / 0.2384\n[0/1][816/938] Loss_D: 0.7788 Loss_G: 2.7324 D(x): 0.7976 D(G(z)): 0.3673 / 0.0755\n[0/1][817/938] Loss_D: 0.5929 Loss_G: 1.6548 D(x): 0.6789 D(G(z)): 0.1291 / 0.2421\n[0/1][818/938] Loss_D: 0.8824 Loss_G: 3.0229 D(x): 0.8235 D(G(z)): 0.4474 / 0.0650\n[0/1][819/938] Loss_D: 0.8679 Loss_G: 0.9974 D(x): 0.5212 D(G(z)): 0.0870 / 0.4133\n[0/1][820/938] Loss_D: 0.8066 Loss_G: 3.1586 D(x): 0.9025 D(G(z)): 0.4516 / 0.0586\n[0/1][821/938] Loss_D: 0.9661 Loss_G: 0.7709 D(x): 0.4933 D(G(z)): 0.1365 / 0.5038\n[0/1][822/938] Loss_D: 1.1345 Loss_G: 3.6494 D(x): 0.9063 D(G(z)): 0.6020 / 0.0357\n[0/1][823/938] Loss_D: 1.2367 Loss_G: 0.3955 D(x): 0.3682 D(G(z)): 0.0841 / 0.7076\n[0/1][824/938] Loss_D: 1.8391 Loss_G: 4.0214 D(x): 0.8945 D(G(z)): 0.7627 / 0.0307\n[0/1][825/938] Loss_D: 2.3562 Loss_G: 0.5504 D(x): 0.1458 D(G(z)): 0.0508 / 0.6400\n[0/1][826/938] Loss_D: 1.4509 Loss_G: 3.4459 D(x): 0.8927 D(G(z)): 0.6746 / 0.0473\n[0/1][827/938] Loss_D: 1.1856 Loss_G: 1.7383 D(x): 0.5085 D(G(z)): 0.1993 / 0.2264\n[0/1][828/938] Loss_D: 0.7650 Loss_G: 1.6374 D(x): 0.7122 D(G(z)): 0.2986 / 0.2528\n[0/1][829/938] Loss_D: 1.0151 Loss_G: 2.4684 D(x): 0.7377 D(G(z)): 0.4309 / 0.1137\n[0/1][830/938] Loss_D: 0.8177 Loss_G: 1.7419 D(x): 0.6225 D(G(z)): 0.2082 / 0.2250\n[0/1][831/938] Loss_D: 0.7516 Loss_G: 1.9770 D(x): 0.7606 D(G(z)): 0.3354 / 0.1662\n[0/1][832/938] Loss_D: 0.7305 Loss_G: 2.1166 D(x): 0.7258 D(G(z)): 0.2869 / 0.1564\n[0/1][833/938] Loss_D: 0.8318 Loss_G: 1.9800 D(x): 0.6750 D(G(z)): 0.2608 / 0.1884\n[0/1][834/938] Loss_D: 0.7306 Loss_G: 2.5852 D(x): 0.8023 D(G(z)): 0.3442 / 0.0918\n[0/1][835/938] Loss_D: 0.8255 Loss_G: 0.8837 D(x): 0.5641 D(G(z)): 0.1319 / 0.4696\n[0/1][836/938] Loss_D: 1.2696 Loss_G: 4.8380 D(x): 0.9454 D(G(z)): 0.6459 / 0.0118\n[0/1][837/938] Loss_D: 1.9604 Loss_G: 0.6260 D(x): 0.1943 D(G(z)): 0.0190 / 0.5876\n[0/1][838/938] Loss_D: 1.1255 Loss_G: 3.1637 D(x): 0.9178 D(G(z)): 0.5924 / 0.0635\n[0/1][839/938] Loss_D: 0.8343 Loss_G: 1.4692 D(x): 0.5858 D(G(z)): 0.1538 / 0.2657\n[0/1][840/938] Loss_D: 0.8437 Loss_G: 2.2262 D(x): 0.7978 D(G(z)): 0.4159 / 0.1314\n[0/1][841/938] Loss_D: 0.9788 Loss_G: 1.3339 D(x): 0.5618 D(G(z)): 0.2501 / 0.3222\n[0/1][842/938] Loss_D: 0.6251 Loss_G: 3.0330 D(x): 0.8827 D(G(z)): 0.3537 / 0.0662\n[0/1][843/938] Loss_D: 0.7196 Loss_G: 1.4131 D(x): 0.6073 D(G(z)): 0.1476 / 0.2843\n[0/1][844/938] Loss_D: 1.0044 Loss_G: 3.3925 D(x): 0.8096 D(G(z)): 0.4768 / 0.0541\n[0/1][845/938] Loss_D: 1.0471 Loss_G: 1.2225 D(x): 0.5039 D(G(z)): 0.1647 / 0.3593\n[0/1][846/938] Loss_D: 0.6955 Loss_G: 3.8719 D(x): 0.9249 D(G(z)): 0.4099 / 0.0287\n[0/1][847/938] Loss_D: 1.0194 Loss_G: 0.7097 D(x): 0.4849 D(G(z)): 0.1095 / 0.5301\n[0/1][848/938] Loss_D: 1.0336 Loss_G: 3.5708 D(x): 0.9412 D(G(z)): 0.5747 / 0.0422\n[0/1][849/938] Loss_D: 0.8042 Loss_G: 1.8332 D(x): 0.5447 D(G(z)): 0.0759 / 0.2020\n[0/1][850/938] Loss_D: 0.5133 Loss_G: 1.7191 D(x): 0.8007 D(G(z)): 0.2255 / 0.2167\n[0/1][851/938] Loss_D: 0.6669 Loss_G: 3.6102 D(x): 0.8722 D(G(z)): 0.3806 / 0.0350\n[0/1][852/938] Loss_D: 1.0131 Loss_G: 1.0570 D(x): 0.4784 D(G(z)): 0.1274 / 0.4060\n[0/1][853/938] Loss_D: 0.9107 Loss_G: 3.3418 D(x): 0.9164 D(G(z)): 0.5119 / 0.0456\n[0/1][854/938] Loss_D: 1.3666 Loss_G: 0.7822 D(x): 0.3426 D(G(z)): 0.0749 / 0.4980\n[0/1][855/938] Loss_D: 1.2779 Loss_G: 3.3932 D(x): 0.9502 D(G(z)): 0.6448 / 0.0478\n[0/1][856/938] Loss_D: 0.8335 Loss_G: 1.4923 D(x): 0.5330 D(G(z)): 0.1083 / 0.2721\n[0/1][857/938] Loss_D: 0.6648 Loss_G: 2.4118 D(x): 0.8402 D(G(z)): 0.3224 / 0.1253\n[0/1][858/938] Loss_D: 0.6679 Loss_G: 2.4944 D(x): 0.7591 D(G(z)): 0.2580 / 0.1025\n[0/1][859/938] Loss_D: 0.7977 Loss_G: 1.3734 D(x): 0.6310 D(G(z)): 0.2076 / 0.3151\n[0/1][860/938] Loss_D: 0.6030 Loss_G: 3.3183 D(x): 0.8777 D(G(z)): 0.3346 / 0.0505\n[0/1][861/938] Loss_D: 0.7571 Loss_G: 1.2517 D(x): 0.5877 D(G(z)): 0.1293 / 0.3347\n[0/1][862/938] Loss_D: 0.7889 Loss_G: 3.3390 D(x): 0.8821 D(G(z)): 0.4312 / 0.0471\n[0/1][863/938] Loss_D: 0.8306 Loss_G: 1.2403 D(x): 0.5508 D(G(z)): 0.1324 / 0.3258\n[0/1][864/938] Loss_D: 0.8038 Loss_G: 3.8881 D(x): 0.8988 D(G(z)): 0.4763 / 0.0294\n[0/1][865/938] Loss_D: 1.1952 Loss_G: 0.9071 D(x): 0.3985 D(G(z)): 0.0661 / 0.4421\n[0/1][866/938] Loss_D: 0.7485 Loss_G: 3.5357 D(x): 0.9156 D(G(z)): 0.4413 / 0.0382\n[0/1][867/938] Loss_D: 0.7097 Loss_G: 1.8585 D(x): 0.6690 D(G(z)): 0.2042 / 0.2087\n[0/1][868/938] Loss_D: 0.8516 Loss_G: 2.5176 D(x): 0.7703 D(G(z)): 0.3743 / 0.1016\n[0/1][869/938] Loss_D: 0.8841 Loss_G: 1.7417 D(x): 0.6327 D(G(z)): 0.2826 / 0.2161\n[0/1][870/938] Loss_D: 0.7450 Loss_G: 3.5046 D(x): 0.8218 D(G(z)): 0.3607 / 0.0413\n[0/1][871/938] Loss_D: 0.6926 Loss_G: 1.2258 D(x): 0.5803 D(G(z)): 0.0680 / 0.3301\n[0/1][872/938] Loss_D: 1.1702 Loss_G: 5.1041 D(x): 0.9300 D(G(z)): 0.5978 / 0.0136\n[0/1][873/938] Loss_D: 1.5729 Loss_G: 0.8530 D(x): 0.3026 D(G(z)): 0.0472 / 0.4805\n[0/1][874/938] Loss_D: 1.0149 Loss_G: 2.8316 D(x): 0.9117 D(G(z)): 0.5443 / 0.0792\n[0/1][875/938] Loss_D: 0.9665 Loss_G: 1.3273 D(x): 0.5268 D(G(z)): 0.1691 / 0.3203\n[0/1][876/938] Loss_D: 0.8105 Loss_G: 3.4346 D(x): 0.8499 D(G(z)): 0.4149 / 0.0472\n[0/1][877/938] Loss_D: 0.7829 Loss_G: 1.4182 D(x): 0.5890 D(G(z)): 0.1541 / 0.2847\n[0/1][878/938] Loss_D: 0.7641 Loss_G: 3.5226 D(x): 0.8523 D(G(z)): 0.4054 / 0.0399\n[0/1][879/938] Loss_D: 0.9262 Loss_G: 0.9129 D(x): 0.4737 D(G(z)): 0.0770 / 0.4464\n[0/1][880/938] Loss_D: 0.9905 Loss_G: 4.1191 D(x): 0.9474 D(G(z)): 0.5521 / 0.0245\n[0/1][881/938] Loss_D: 0.9256 Loss_G: 0.8608 D(x): 0.4944 D(G(z)): 0.1031 / 0.4828\n[0/1][882/938] Loss_D: 1.1168 Loss_G: 4.4614 D(x): 0.9264 D(G(z)): 0.5869 / 0.0172\n[0/1][883/938] Loss_D: 1.2152 Loss_G: 1.0341 D(x): 0.4004 D(G(z)): 0.0670 / 0.4172\n[0/1][884/938] Loss_D: 0.9935 Loss_G: 3.3061 D(x): 0.8845 D(G(z)): 0.5235 / 0.0492\n[0/1][885/938] Loss_D: 0.8200 Loss_G: 1.5939 D(x): 0.5622 D(G(z)): 0.1435 / 0.2644\n[0/1][886/938] Loss_D: 0.6264 Loss_G: 2.4535 D(x): 0.8287 D(G(z)): 0.3104 / 0.1039\n[0/1][887/938] Loss_D: 0.6421 Loss_G: 2.1645 D(x): 0.7394 D(G(z)): 0.2424 / 0.1488\n[0/1][888/938] Loss_D: 0.8348 Loss_G: 1.8236 D(x): 0.6831 D(G(z)): 0.3038 / 0.1955\n[0/1][889/938] Loss_D: 0.5388 Loss_G: 2.4613 D(x): 0.8009 D(G(z)): 0.2400 / 0.1060\n[0/1][890/938] Loss_D: 0.4540 Loss_G: 2.3579 D(x): 0.8033 D(G(z)): 0.1851 / 0.1142\n[0/1][891/938] Loss_D: 0.5416 Loss_G: 2.3522 D(x): 0.7890 D(G(z)): 0.2327 / 0.1218\n[0/1][892/938] Loss_D: 0.6216 Loss_G: 2.3510 D(x): 0.7741 D(G(z)): 0.2633 / 0.1145\n[0/1][893/938] Loss_D: 0.5228 Loss_G: 1.4372 D(x): 0.7063 D(G(z)): 0.1237 / 0.2745\n[0/1][894/938] Loss_D: 0.7789 Loss_G: 5.8767 D(x): 0.9324 D(G(z)): 0.4694 / 0.0040\n[0/1][895/938] Loss_D: 1.8364 Loss_G: 1.0212 D(x): 0.2090 D(G(z)): 0.0109 / 0.4794\n[0/1][896/938] Loss_D: 1.0707 Loss_G: 3.8828 D(x): 0.8862 D(G(z)): 0.4996 / 0.0297\n[0/1][897/938] Loss_D: 1.5392 Loss_G: 0.1729 D(x): 0.3308 D(G(z)): 0.1034 / 0.8557\n[0/1][898/938] Loss_D: 2.2989 Loss_G: 4.3062 D(x): 0.9615 D(G(z)): 0.8420 / 0.0265\n[0/1][899/938] Loss_D: 2.0006 Loss_G: 0.6075 D(x): 0.2209 D(G(z)): 0.0802 / 0.5869\n[0/1][900/938] Loss_D: 1.4379 Loss_G: 1.6414 D(x): 0.8221 D(G(z)): 0.6475 / 0.2339\n[0/1][901/938] Loss_D: 1.2200 Loss_G: 1.6200 D(x): 0.5623 D(G(z)): 0.3902 / 0.2288\n[0/1][902/938] Loss_D: 1.1418 Loss_G: 1.3712 D(x): 0.5392 D(G(z)): 0.3390 / 0.3226\n[0/1][903/938] Loss_D: 1.2097 Loss_G: 1.9904 D(x): 0.6982 D(G(z)): 0.4851 / 0.1769\n[0/1][904/938] Loss_D: 0.9806 Loss_G: 1.6086 D(x): 0.5956 D(G(z)): 0.2928 / 0.2494\n[0/1][905/938] Loss_D: 1.0078 Loss_G: 1.7199 D(x): 0.6707 D(G(z)): 0.3781 / 0.2221\n[0/1][906/938] Loss_D: 1.0089 Loss_G: 1.8885 D(x): 0.6643 D(G(z)): 0.3977 / 0.1810\n[0/1][907/938] Loss_D: 1.0099 Loss_G: 1.5111 D(x): 0.5964 D(G(z)): 0.3181 / 0.2547\n[0/1][908/938] Loss_D: 1.1638 Loss_G: 1.9865 D(x): 0.6315 D(G(z)): 0.4176 / 0.1706\n[0/1][909/938] Loss_D: 0.8976 Loss_G: 1.2770 D(x): 0.5880 D(G(z)): 0.2233 / 0.3376\n[0/1][910/938] Loss_D: 1.0154 Loss_G: 3.7182 D(x): 0.8825 D(G(z)): 0.5292 / 0.0389\n[0/1][911/938] Loss_D: 1.1078 Loss_G: 1.0099 D(x): 0.4037 D(G(z)): 0.0744 / 0.4420\n[0/1][912/938] Loss_D: 1.0717 Loss_G: 2.3526 D(x): 0.8916 D(G(z)): 0.5293 / 0.1264\n[0/1][913/938] Loss_D: 0.7907 Loss_G: 2.2550 D(x): 0.6793 D(G(z)): 0.2576 / 0.1477\n[0/1][914/938] Loss_D: 1.1322 Loss_G: 1.4895 D(x): 0.5802 D(G(z)): 0.3362 / 0.2650\n[0/1][915/938] Loss_D: 0.7800 Loss_G: 2.1535 D(x): 0.7221 D(G(z)): 0.3042 / 0.1542\n[0/1][916/938] Loss_D: 0.7081 Loss_G: 3.0047 D(x): 0.7943 D(G(z)): 0.3388 / 0.0727\n[0/1][917/938] Loss_D: 0.7730 Loss_G: 1.2411 D(x): 0.6215 D(G(z)): 0.1585 / 0.3445\n[0/1][918/938] Loss_D: 1.2387 Loss_G: 4.5333 D(x): 0.9017 D(G(z)): 0.5975 / 0.0167\n[0/1][919/938] Loss_D: 1.7213 Loss_G: 0.9698 D(x): 0.2348 D(G(z)): 0.0474 / 0.4456\n[0/1][920/938] Loss_D: 0.9340 Loss_G: 2.9415 D(x): 0.9009 D(G(z)): 0.5054 / 0.0746\n[0/1][921/938] Loss_D: 0.6452 Loss_G: 3.2503 D(x): 0.7618 D(G(z)): 0.2630 / 0.0552\n[0/1][922/938] Loss_D: 1.2843 Loss_G: 0.3709 D(x): 0.3941 D(G(z)): 0.1076 / 0.7199\n[0/1][923/938] Loss_D: 2.1893 Loss_G: 4.7920 D(x): 0.9843 D(G(z)): 0.8388 / 0.0161\n[0/1][924/938] Loss_D: 1.3681 Loss_G: 1.4399 D(x): 0.3328 D(G(z)): 0.0556 / 0.2853\n[0/1][925/938] Loss_D: 0.9469 Loss_G: 2.9389 D(x): 0.8787 D(G(z)): 0.4983 / 0.0728\n[0/1][926/938] Loss_D: 0.7754 Loss_G: 2.0616 D(x): 0.6356 D(G(z)): 0.2097 / 0.1593\n[0/1][927/938] Loss_D: 0.7952 Loss_G: 2.5814 D(x): 0.7366 D(G(z)): 0.3436 / 0.0942\n[0/1][928/938] Loss_D: 0.8147 Loss_G: 1.4341 D(x): 0.6037 D(G(z)): 0.1965 / 0.2818\n[0/1][929/938] Loss_D: 0.8069 Loss_G: 3.4426 D(x): 0.8721 D(G(z)): 0.4598 / 0.0395\n[0/1][930/938] Loss_D: 1.0073 Loss_G: 1.3063 D(x): 0.4711 D(G(z)): 0.1182 / 0.3156\n[0/1][931/938] Loss_D: 0.7312 Loss_G: 2.5156 D(x): 0.8579 D(G(z)): 0.3896 / 0.1052\n[0/1][932/938] Loss_D: 0.7941 Loss_G: 2.0064 D(x): 0.6705 D(G(z)): 0.2383 / 0.1654\n[0/1][933/938] Loss_D: 0.7325 Loss_G: 2.2908 D(x): 0.7588 D(G(z)): 0.3105 / 0.1215\n[0/1][934/938] Loss_D: 0.6184 Loss_G: 1.9800 D(x): 0.7216 D(G(z)): 0.2107 / 0.1732\n[0/1][935/938] Loss_D: 0.6846 Loss_G: 1.9613 D(x): 0.7502 D(G(z)): 0.2832 / 0.1723\n[0/1][936/938] Loss_D: 0.8359 Loss_G: 1.6392 D(x): 0.6480 D(G(z)): 0.2535 / 0.2352\n[0/1][937/938] Loss_D: 0.7550 Loss_G: 4.8355 D(x): 0.9058 D(G(z)): 0.4228 / 0.0117\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n","metadata":{},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}